---
title: "ZOOTask_EDA_modeling_12.05.23"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
#  `echo = FALSE` to prevent printing of the R code that generated the plot.
```

## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:


```{r}

# Load required packages

# install.packages("dplyr")
# install.packages("Hmisc")
# install.packages("Matrix")
# install.packages("ggplot2")
# install.packages("emmeans")
# install.packages("lsmeans")
# install.packages("effects")
# install.packages("nlme")
# install.packages("lme4")
# install.packages("lmerTest")
# install.packages("sjPlot")
# install.packages("stats")
# install.packages("lmerTest")

library(dplyr, quietly = TRUE, warn.conflicts = FALSE)
library(Hmisc, quietly = TRUE, warn.conflicts = FALSE)
library(ggplot2, quietly = TRUE, warn.conflicts = FALSE)
library(emmeans, quietly = TRUE, warn.conflicts = FALSE)
library(lsmeans, quietly = TRUE, warn.conflicts = FALSE)
library(effects, quietly = TRUE, warn.conflicts = FALSE)
library(Matrix, quietly = TRUE, warn.conflicts = FALSE)
# library(nlme, quietly = TRUE, warn.conflicts = FALSE)
library(lme4, quietly = TRUE, warn.conflicts = FALSE)
library(lmerTest, quietly = TRUE, warn.conflicts = FALSE)
library(sjPlot, quietly = TRUE, warn.conflicts = FALSE)
library(stats, quietly = TRUE, warn.conflicts = FALSE)


```

# LOAD ZOO_GOOD DATAFRAME
```{r}
ZOO_good <- read.csv(file = '/Users/aysuerdemir/Desktop/R workspace/ERP_Zoo/CrossSectional/Mix/ZOO_good.csv')
# Remove the added X variable after reading it back into R:
ZOO_good <- ZOO_good %>%
  dplyr::select(-X)
# Display the first 6 rows of te final dataset:
head(ZOO_good)
print(names(ZOO_good))

```
# CREATE DATASETS FOR:
1) ERP and BEHAVIORAL ANALYSES --> ZOO_FCz_Pz
2) AGE-GENDER ANALYSES --> ZOO_age_gender

```{r}
# DATAFRAME FOR ERP and BEHAVIORAL ANALYSES:
ZOO_FCz_Pz <- subset(ZOO_good, (Laterality == "Midline"))
rownames(ZOO_FCz_Pz) <- NULL # reset index

# DATAFRAME FOR AGE-GENDER ANALYSES:
# Create a dataset with only 1 entry for each subject:
# Pick one condition - randomly -  because we are only working on age and gender for this one:
ZOO_age_gender <- subset(ZOO_FCz_Pz, (Trial.Type == "NegGo"))
rownames(ZOO_age_gender) <- NULL # reset index

```

# DISCRIPTIVE STATISTICS FOR AGE, GENDER

```{r}

# Give Age, Gender and Count Summary Statistics for each Group:
ZOO_age_gender_summary <- 
  ZOO_age_gender %>%
  group_by(talkergroup_final) %>%
summarise(
    age = mean(calculator_age_cve, na.rm = TRUE),
    min_age = min(calculator_age_cve, na.rm = TRUE),
    max_age = max(calculator_age_cve, na.rm = TRUE),
    male_gender_count = sum(calculator_gender_cve, na.rm = TRUE),  # because male = 1, female = 0
    SD_age = sd(calculator_age_cve, na.rm = TRUE),
    Count_kids = n_distinct(Subject)
    )
print(ZOO_age_gender_summary)



# Histogram of Age across all participants
hist(ZOO_age_gender$calculator_age_cve, 
     main = "Histogram of Age",
     xlab = "age in months",
     ylab = "Frequency",
     col = "blue",        # Color of bars
     border = "black",    # Border color of bars
     # xlim = c(min_value, max_value),  # Adjust the x-axis limits if needed
     breaks = 12)  

# print(quantile(ZOO$calculator_age_cve, 0.50, na.rm = TRUE),)

# CREATE TWO PLOTS FOR CWS AND CWNS
# Create a new plot
par(mfrow=c(1,2))  # This sets up a 1x2 grid for side-by-side histograms
# Histogram for talkergroup_final == 1
hist(ZOO_age_gender$calculator_age_cve[ZOO_age_gender$talkergroup_final == 0], 
     main = "Histogram for CWNS",
     xlab = "age in months",
     ylab = "Frequency",
     col = "blue",
     border = "black",
     xlim = c(30, 100), 
     breaks = 12)
# Histogram for talkergroup_final == 2
hist(ZOO_age_gender$calculator_age_cve[ZOO_age_gender$talkergroup_final == 1], 
     main = "Histogram for CWS",
     xlab = "age in months",
     ylab = "Frequency",
     col = "red",  # Use a different color for the second group
     border = "black",
     xlim = c(30, 100), 
     breaks = 12)
# Reset the plotting to a single plot
par(mfrow=c(1,1))


# MAKE SURE AGE DOES NOT DIFFER BETWEEN GROUPS USING ANOVA
model <- aov (calculator_age_cve ~ talkergroup_final, data = ZOO_age_gender)
anova(model)

# MAKE SURE AGE DOES NOT DIFFER BETWEEN GROUPS USING T-Test  
# Subset the data into two groups based on talkergroup_final
group_CWNS <- ZOO_age_gender$calculator_age_cve[ZOO_age_gender$talkergroup_final == 0]
group_CWS <- ZOO_age_gender$calculator_age_cve[ZOO_age_gender$talkergroup_final == 1]
# Perform a two-sample t-test
t_test_result <- t.test(group_CWNS, group_CWS, alternative = "two.sided")
# Display the t-test result
print(t_test_result)

```

# BEHAVIORAL DATA SUMMARY STATISTICS

```{r}
# Histogram of Accuracy, premature_responses, and RT_proper

summary_behavioral_hist <-
  ZOO_FCz_Pz %>%
  group_by(Subject, talkergroup_final, Trial.Type) %>%
  summarise(Average_accuracy = mean(accuracy, na.rm = TRUE), 
            Average_premature_responses = mean(premature_responses, na.rm = TRUE),
            Sensitivity = mean(sensitivity, na.rm = TRUE),
            Average_RT = mean(RT_proper, na.rm = TRUE))
print(summary_behavioral_hist)


# Sensitivity Histogram:
# Create a new plot
par(mfrow=c(1,2))  # This sets up a 1x2 grid for side-by-side histograms
# Histogram for talkergroup_final == 0
hist(summary_behavioral_hist$Sensitivity[summary_behavioral_hist$talkergroup_final == 0], 
     main = "Histogram for CWNS",
     xlab = "Sensitivity",
     ylab = "Frequency",
     col = "blue",
     border = "black",
     #xlim = c(0, 100), 
     #ylim = c(0, 50),  
     breaks = 12)
# Histogram for talkergroup_final == 1
hist(summary_behavioral_hist$Sensitivity[summary_behavioral_hist$talkergroup_final == 1], 
     main = "Histogram for CWS",
     xlab = "Sensitivity",
     ylab = "Frequency",
     col = "red",  # Use a different color for the second group
     border = "black",
     #xlim = c(0, 100), 
     #ylim = c(0, 50),  
     breaks = 12)
# Reset the plotting to a single plot
par(mfrow=c(1,1))



# Accuracy Histogram:
# Create a new plot
par(mfrow=c(1,2))  # This sets up a 1x2 grid for side-by-side histograms
# Histogram for talkergroup_final == 0
hist(summary_behavioral_hist$Average_accuracy[summary_behavioral_hist$talkergroup_final == 0], 
     main = "Histogram for CWNS",
     xlab = "accuracy",
     ylab = "Frequency",
     col = "blue",
     border = "black",
     xlim = c(0, 100), 
     ylim = c(0, 50),  
     breaks = 12)
# Histogram for talkergroup_final == 1
hist(summary_behavioral_hist$Average_accuracy[summary_behavioral_hist$talkergroup_final == 1], 
     main = "Histogram for CWS",
     xlab = "accuracy",
     ylab = "Frequency",
     col = "red",  # Use a different color for the second group
     border = "black",
     xlim = c(0, 100), 
     ylim = c(0, 50),  
     breaks = 12)
# Reset the plotting to a single plot
par(mfrow=c(1,1))

# Scatterplot of all accuracy across all participants
scatterplot <- ggplot(summary_behavioral_hist, aes(x = Subject, y = Average_accuracy, color = Trial.Type)) +
  geom_point() +
  scale_y_continuous(limits = c(0, 100), breaks = seq(0, 100, by = 10))
plot(scatterplot)


# Premature responses Histogram:
# Create a new plot
par(mfrow=c(1,2))  
# Histogram for talkergroup_final == 0
hist(summary_behavioral_hist$Average_premature_responses[summary_behavioral_hist$talkergroup_final == 0], 
     main = "Histogram for CWNS",
     xlab = "premature_responses",
     ylab = "Frequency",
     col = "blue",
     border = "black",
     xlim = c(0, 50), 
     ylim = c(0, 150),  
     breaks = 12)
# Histogram for talkergroup_final == 1
hist(summary_behavioral_hist$Average_premature_responses[summary_behavioral_hist$talkergroup_final == 1], 
     main = "Histogram for CWS",
     xlab = "premature_responses",
     ylab = "Frequency",
     col = "red",  # Use a different color for the second group
     border = "black",
     xlim = c(0, 50), 
     ylim = c(0, 150),  
     breaks = 12)
# Reset the plotting to a single plot
par(mfrow=c(1,1))

# Scatterplot of all accuracy across all participants
scatterplot <- ggplot(summary_behavioral_hist, aes(x = Subject, y = Average_premature_responses, color = Trial.Type)) +
  geom_point() +
  scale_y_continuous(limits = c(0, 50), breaks = seq(0, 50, by = 10))
plot(scatterplot)


#Reaction Time Histogram:
# Create a new plot
par(mfrow=c(1,2))  
# Histogram for talkergroup_final == 0
hist(summary_behavioral_hist$Average_RT[summary_behavioral_hist$talkergroup_final == 0], 
     main = "Histogram for CWNS",
     xlab = "reaction_time",
     ylab = "Frequency",
     col = "blue",
     border = "black",
     xlim = c(100, 2000), 
     ylim = c(0, 50),  
     breaks = 12)
# Histogram for talkergroup_final == 1
hist(summary_behavioral_hist$Average_RT[summary_behavioral_hist$talkergroup_final == 1], 
     main = "Histogram for CWS",
     xlab = "reaction_time",
     ylab = "Frequency",
     col = "red",  # Use a different color for the second group
     border = "black",
     xlim = c(100, 2000), 
     ylim = c(0, 50),  
     breaks = 12)
# Reset the plotting to a single plot
par(mfrow=c(1,1))

# Scatterplot of all reaction time across all participants
scatterplot <- ggplot(summary_behavioral_hist, aes(x = Subject, y = Average_RT, color = Trial.Type)) +
  geom_point() +
  scale_y_continuous(limits = c(200, 2000), breaks = seq(200, 2000, by = 200))
plot(scatterplot)

```


# BARPLOTS FOR BEHAVIORAL DATA:

```{r}

# Create the Dataframe to get the behavioral data
summary_behavioral <- 
  ZOO_FCz_Pz%>%
  group_by(talkergroup_final, Emotion, Condition) %>%
  summarise(
    Average_accuracy = mean(accuracy, na.rm = TRUE),
    SEM_accuracy = sd(accuracy, na.rm = TRUE) / sqrt(n()),
    Average_hit_falsealarm = mean(hit_falsealarm, na.rm = TRUE),
    SEM_hit_falsealarm = sd(hit_falsealarm, na.rm = TRUE) / sqrt(n()),
    Average_premature_responses = mean(premature_responses, na.rm = TRUE),
    SEM_premature_responses = sd(premature_responses, na.rm = TRUE) / sqrt(n()),
    Average_RT_proper = mean(RT_proper, na.rm = TRUE),
    SEM_RT_proper = sd(RT_proper, na.rm = TRUE) / sqrt(n()),
    Average_RT_premature = mean(RT_premature, na.rm = TRUE),
    SEM_RT_premature = sd(RT_premature, na.rm = TRUE) / sqrt(n()),
    )

# Rename some factors for better visuals:
summary_behavioral$talkergroup_final <- factor(summary_behavioral$talkergroup_final, levels = c(0, 1), labels = c("CWNS", "CWS"))
summary_behavioral$Emotion <- factor(summary_behavioral$Emotion, levels = c("Neg", "Neut"), labels = c("Affective", "Neutral"))


# Create the Dataframe to get the behavioral data
summary_sensitivity <- 
  ZOO_FCz_Pz%>%
  group_by(talkergroup_final, Emotion) %>%
  summarise(
    Average_sensitivity = mean(sensitivity, na.rm = TRUE),
    SEM_sensitivity = sd(sensitivity, na.rm = TRUE) / sqrt(n()),
    )

# Rename some factors for better visuals:
summary_sensitivity$talkergroup_final <- factor(summary_sensitivity$talkergroup_final, levels = c(0, 1), labels = c("CWNS", "CWS"))
summary_sensitivity$Emotion <- factor(summary_sensitivity$Emotion, levels = c("Neg", "Neut"), labels = c("Affective", "Neutral"))


# BAR PLOT FOR SENSITIVITY
bar_plot <- ggplot(summary_sensitivity, aes(x = talkergroup_final, y = Average_sensitivity)) +
  geom_bar(stat = "identity", position = "dodge",  width = 0.5, fill ='royalblue2') +
  geom_errorbar(aes(ymin = Average_sensitivity - SEM_sensitivity, ymax = Average_sensitivity + SEM_sensitivity), width = 0.2, position = position_dodge(width = 0.7)) +
  labs(x = "Talkergroup", y = "Sensitivity (d')") +
  facet_grid(. ~ Emotion) +
  theme_minimal() +
  theme(
    axis.text = element_text(size = 14, color = "black"),
    axis.title = element_text(size = 14),
    legend.title =element_blank(),
    legend.text = element_text(size = 14),
    plot.title = element_text(hjust = 0.5, size = 14, face = "bold", vjust = 2),
    strip.text = element_text(size = 14, face = "bold")) +
  ggtitle("Sensitivity by Emotion  for CWS and CWNS") 
  
bar_plot <- bar_plot + coord_cartesian(ylim = c(1,3))
print(bar_plot)


# Sensitivity takes into account both the hit rate (correctly identifying the target stimulus) and the false alarm rate (incorrectly responding to the non-target stimulus), and provides a more nuanced measure of the participant's performance than accuracy alone.

# Measuring sensitivity using hit rate and false alarm rate in the context of a go nogo task provides information about the individual's ability to distinguish between the target stimulus (go) and the non-target stimulus (nogo). It allows us to assess how well the individual can detect and respond to the relevant stimulus (go), while inhibiting responses to the irrelevant stimulus (nogo). This information can be useful in identifying individuals with attentional deficits or impulsivity, as they may have a higher false alarm rate, indicating difficulty in inhibiting responses to the nogo stimulus. It can also provide insights into the cognitive processes involved in response inhibition and decision-making.

# High Sensitivity: Indicates a high ability to correctly identify Go stimuli (hits) while minimizing false alarms to No-Go stimuli. This is generally desirable as it reflects a high level of accuracy in distinguishing between Go and No-Go trials.

# Low Sensitivity: Suggests a lower ability to differentiate between Go and No-Go stimuli. This could mean more misses (failing to respond to Go stimuli) and/or more false alarms (responding to No-Go stimuli). In the context of a Go/No-Go task, a low sensitivity measure could be indicative of a reduced ability to discriminate between the two types of stimuli.

# High Sensitivity: The participant or model is effective at accurately responding to Go stimuli while correctly refraining from responding to No-Go stimuli.

# Low Sensitivity: The participant or model may struggle to distinguish Go stimuli from No-Go stimuli, leading to more errors, such as misses (failing to respond to Go stimuli) and false alarms (incorrectly responding to No-Go stimuli).


# BAR PLOT FOR ACCURACY
bar_plot <- ggplot(summary_behavioral, aes(x = Emotion, y = Average_accuracy, fill = Condition)) +
  geom_bar(stat = "identity", position = "dodge", width = 0.7) +
  geom_errorbar(aes(ymin = Average_accuracy - SEM_accuracy, ymax = Average_accuracy + SEM_accuracy), width = 0.2, position = position_dodge(width = 0.7)) +
  labs(x = "Emotion", y = "Average Accuracy (%)") +
  facet_grid(. ~ talkergroup_final) +
  theme_minimal() +
  theme(
    axis.text = element_text(size = 14, color = "black"),
    axis.title = element_text(size = 14),
    legend.title =element_blank(),
    legend.text = element_text(size = 14),
    plot.title = element_text(hjust = 0.5, size = 14, face = "bold", vjust = 2),
    strip.text = element_text(size = 14, face = "bold")) +
  scale_fill_manual(values = c("royalblue2", "orangered", "royalblue2", "orangered", "royalblue2", "orangered", "royalblue2", "orangered"))
# ggtitle("Average Accuracy by Emotion and Condition for CWS and CWNS") 
bar_plot <- bar_plot + coord_cartesian(ylim = c(50, 100))
print(bar_plot)


bar_plot <- ggplot(summary_behavioral, aes(x = Emotion, y = Average_accuracy, fill = talkergroup_final)) +
  geom_bar(stat = "identity", position = "dodge", width = 0.7) +
  geom_errorbar(aes(ymin = Average_accuracy - SEM_accuracy, ymax = Average_accuracy + SEM_accuracy), width = 0.2, position = position_dodge(width = 0.7)) +
  labs(x = "Emotion", y = "Average Accuracy (%)") +
  facet_grid(. ~ Condition) +
  theme_minimal() +
  theme(
    axis.text = element_text(size = 14, color = "black"),
    axis.title = element_text(size = 14),
    legend.title =element_blank(),
    legend.text = element_text(size = 14),
    plot.title = element_text(hjust = 0.5, size = 14, face = "bold", vjust = 2),
    strip.text = element_text(size = 14, face = "bold")) +
  scale_fill_manual(values = c("royalblue2", "orangered", "royalblue2", "orangered", "royalblue2", "orangered", "royalblue2", "orangered"))
# ggtitle("Average Accuracy by Emotion and Condition for CWS and CWNS") 
bar_plot <- bar_plot + coord_cartesian(ylim = c(50, 100))
print(bar_plot)


# BAR PLOT FOR HIT AND FALSE ALARM ONLY FOR NOGO
summary_behavioral_NoGo <- subset(summary_behavioral, Condition == "NoGo")

bar_plot <- ggplot(summary_behavioral_NoGo, aes(x = talkergroup_final, y = Average_hit_falsealarm, fill = Emotion)) +
  geom_bar(stat = "identity", position = "dodge", width = 0.5, fill ='royalblue2') +
  geom_errorbar(aes(ymin = Average_hit_falsealarm - SEM_hit_falsealarm, ymax = Average_hit_falsealarm + SEM_hit_falsealarm), width = 0.2, position = position_dodge(width = 0.9)) +
  labs(x = "Emotion", y = "False Alarm Rate - NoGo") +
  facet_grid(. ~ Emotion) +
  theme_minimal() +
  theme(
    axis.text = element_text(size = 14, color = "black"),
    axis.title = element_text(size = 14),
    legend.title =element_blank(),
    legend.text = element_text(size = 14),
    plot.title = element_text(hjust = 0.5, size = 14, face = "bold", vjust = 2),
    strip.text = element_text(size = 14, face = "bold")) 
# ggtitle("Average Accuracy by Emotion and Condition for CWS and CWNS") 
# bar_plot <- bar_plot + coord_cartesian(ylim = c(650, 850))
print(bar_plot)



# BAR PLOT FOR PREMATURE RESPONSES
bar_plot <- ggplot(summary_behavioral, aes(x = Emotion, y = Average_premature_responses, fill = Condition)) +
  geom_bar(stat = "identity", position = "dodge", width = 0.7) +
  geom_errorbar(aes(ymin = Average_premature_responses - SEM_premature_responses, ymax = Average_premature_responses + SEM_premature_responses), width = 0.2, position = position_dodge(width = 0.7)) +
  labs(x = "Emotion", y = "Proportion of Premature Responses (%)") +
  facet_grid(. ~ talkergroup_final) +
  theme_minimal() +
  theme(
    axis.text = element_text(size = 14, color = "black"),
    axis.title = element_text(size = 14),
    legend.title =element_blank(),
    legend.text = element_text(size = 14),
    plot.title = element_text(hjust = 0.5, size = 14, face = "bold", vjust = 2),
    strip.text = element_text(size = 14, face = "bold")) +
  scale_fill_manual(values = c("royalblue2", "orangered", "royalblue2", "orangered", "royalblue2", "orangered", "royalblue2", "orangered"))
# ggtitle("Average Accuracy by Emotion and Condition for CWS and CWNS") 
bar_plot <- bar_plot + coord_cartesian(ylim = c(0, 10))
print(bar_plot)

# BAR PLOT FOR PREMATURE RESPONSES 

summary_behavioral$Condition <- factor(summary_behavioral$Condition, levels = c("Go", "NoGo"), labels = c("Go Correct", "NoGo Incorrect"))

bar_plot <- ggplot(summary_behavioral, aes(x = Emotion, y = Average_premature_responses, fill = talkergroup_final)) +
  geom_bar(stat = "identity", position = "dodge", width = 0.7) +
  geom_errorbar(aes(ymin = Average_premature_responses - SEM_premature_responses, ymax = Average_premature_responses + SEM_premature_responses), width = 0.2, position = position_dodge(width = 0.7)) +
  labs(x = "Emotion", y = "Premature Responses (proportion %)") +
  facet_grid(. ~ Condition) +
  theme_minimal() +
  theme(
    axis.text = element_text(size = 14, color = "black"),
    axis.title = element_text(size = 14),
    legend.title =element_blank(),
    legend.text = element_text(size = 14),
    plot.title = element_text(hjust = 0.5, size = 14, face = "bold", vjust = 2),
    strip.text = element_text(size = 14, face = "bold")) +
  scale_fill_manual(values = c("royalblue2", "orangered", "royalblue2", "orangered", "royalblue2", "orangered", "royalblue2", "orangered"))
# ggtitle("Average Premature Responses by Emotion and Condition for CWS and CWNS") 
bar_plot <- bar_plot + coord_cartesian(ylim = c(0, 10))
print(bar_plot)

# BAR PLOT FOR premature_responses - GO ONLY
summary_behavioral_Go <- subset(summary_behavioral, Condition == "Go Correct")

bar_plot <- ggplot(summary_behavioral_Go, aes(x = talkergroup_final, y = Average_premature_responses, fill = Emotion)) +
  geom_bar(stat = "identity", position = "dodge", width = 0.5, fill ='royalblue2') +
  geom_errorbar(aes(ymin = Average_premature_responses - SEM_premature_responses, ymax = Average_premature_responses + SEM_premature_responses), width = 0.2, position = position_dodge(width = 0.9)) +
  labs(x = "talkergroup_final", y = "Average premature_responses rate % - GO") +
  facet_grid(. ~ Emotion) +
  theme_minimal() +
  theme(
    axis.text = element_text(size = 14, color = "black"),
    axis.title = element_text(size = 14),
    legend.title =element_blank(),
    legend.text = element_text(size = 14),
    plot.title = element_text(hjust = 0.5, size = 14, face = "bold", vjust = 2),
    strip.text = element_text(size = 14, face = "bold")) 
# ggtitle("Average Accuracy by Emotion and Condition for CWS and CWNS") 
# bar_plot <- bar_plot + coord_cartesian(ylim = c(650, 850))
print(bar_plot)


# BAR PLOT FOR REACTION TIME - GO ONLY
bar_plot <- ggplot(summary_behavioral_Go, aes(x = Emotion, y = Average_RT_proper, fill = talkergroup_final)) +
  geom_bar(stat = "identity", position = "dodge", width = 0.5, fill ='royalblue2') +
  geom_errorbar(aes(ymin = Average_RT_proper - SEM_RT_proper, ymax = Average_RT_proper + SEM_RT_proper), width = 0.2, position = position_dodge(width = 0.9)) +
  labs(x = "Emotion", y = "Average Reaction Time (ms) - GO correct") +
  facet_grid(. ~ talkergroup_final) +
  theme_minimal() +
  theme(
    axis.text = element_text(size = 14, color = "black"),
    axis.title = element_text(size = 14),
    legend.title =element_blank(),
    legend.text = element_text(size = 14),
    plot.title = element_text(hjust = 0.5, size = 14, face = "bold", vjust = 2),
    strip.text = element_text(size = 14, face = "bold")) 
# ggtitle("Average Accuracy by Emotion and Condition for CWS and CWNS") 
bar_plot <- bar_plot + coord_cartesian(ylim = c(650, 850))
print(bar_plot)

# BAR PLOT FOR REACTION TIME - both go and nogo

bar_plot <- ggplot(summary_behavioral, aes(x = Emotion, y = Average_RT_proper, fill = talkergroup_final)) +
  geom_bar(stat = "identity", position = "dodge", width = 0.7) +
  geom_errorbar(aes(ymin = Average_RT_proper - SEM_RT_proper, ymax = Average_RT_proper + SEM_RT_proper), width = 0.2, position = position_dodge(width = 0.7)) +
  labs(x = "Emotion", y = "Average Reaction Time (ms)") +
  facet_grid(. ~ Condition) +
  theme_minimal() +
  theme(
    axis.text = element_text(size = 14, color = "black"),
    axis.title = element_text(size = 14),
    legend.title =element_blank(),
    legend.text = element_text(size = 14),
    plot.title = element_text(hjust = 0.5, size = 14, face = "bold", vjust = 2),
    strip.text = element_text(size = 14, face = "bold")) +
  scale_fill_manual(values = c("royalblue2", "orangered", "royalblue2", "orangered", "royalblue2", "orangered", "royalblue2", "orangered"))
# ggtitle("Average Accuracy by Emotion and Condition for CWS and CWNS") 
bar_plot <- bar_plot + coord_cartesian(ylim = c(500, 850))
print(bar_plot)


# BAR PLOT FOR Premature Responses REACTION TIME

bar_plot <- ggplot(summary_behavioral, aes(x = Emotion, y = Average_RT_premature, fill = talkergroup_final)) +
  geom_bar(stat = "identity", position = "dodge", width = 0.7) +
  geom_errorbar(aes(ymin = Average_RT_premature - SEM_RT_premature, ymax = Average_RT_premature + SEM_RT_premature), width = 0.2, position = position_dodge(width = 0.7)) +
  labs(x = "Emotion", y = "Premature responses - Average Reaction Time (ms)") +
  facet_grid(. ~ Condition) +
  theme_minimal() +
  theme(
    axis.text = element_text(size = 14, color = "black"),
    axis.title = element_text(size = 14),
    legend.title =element_blank(),
    legend.text = element_text(size = 14),
    plot.title = element_text(hjust = 0.5, size = 14, face = "bold", vjust = 2),
    strip.text = element_text(size = 14, face = "bold")) +
  scale_fill_manual(values = c("royalblue2", "orangered", "royalblue2", "orangered", "royalblue2", "orangered", "royalblue2", "orangered"))
# ggtitle("Average Accuracy by Emotion and Condition for CWS and CWNS") 
# bar_plot <- bar_plot + coord_cartesian(ylim = c(500, 850))
print(bar_plot)



```

# BEHAVIORAL ANALYSES 
The warning "non-integer counts in a binomial glm!" is because the `glmer()` function with `family = binomial` expects the response to be counts of successes and failures, which should be integers. However, in your model, `accuracy_prop` and `1 - accuracy_prop` are proportions, not counts, so they are not integers.




# BEHAVIORAL ANALYSES - ACCURACY
# Since accuracy data is highly skewed use Wilcox test

```{r}
# ACCURACY

ZOO_FCz_Pz_NOGO <- subset(ZOO_FCz_Pz, (Condition == "NoGo" & (Emotion == "Neut" | Emotion == "Neg")))
ZOO_FCz_Pz_GO <- subset(ZOO_FCz_Pz, (Condition == "Go" & (Emotion == "Neut" | Emotion == "Neg")))

ZOO_FCz_Pz_NOGO_neut <- subset(ZOO_FCz_Pz, (Condition == "NoGo" & Emotion == "Neut"))
ZOO_FCz_Pz_NOGO_aff <- subset(ZOO_FCz_Pz, (Condition == "NoGo" & Emotion == "Neg"))
ZOO_FCz_Pz_GO_neut <- subset(ZOO_FCz_Pz, (Condition == "Go" & Emotion == "Neut"))
ZOO_FCz_Pz_GO_aff <- subset(ZOO_FCz_Pz, (Condition == "Go" & Emotion == "Neg"))


library(stats)

# Perform the Mann-Whitney U test

# ACCURACY
mwu_result <- wilcox.test(accuracy ~ talkergroup_final, data = ZOO_FCz_Pz_NOGO_neut)
print(mwu_result)
mwu_result <- wilcox.test(accuracy ~ talkergroup_final, data = ZOO_FCz_Pz_NOGO_aff)
print(mwu_result)
mwu_result <- wilcox.test(accuracy ~ talkergroup_final, data = ZOO_FCz_Pz_GO_neut)
print(mwu_result)
mwu_result <- wilcox.test(accuracy ~ talkergroup_final, data = ZOO_FCz_Pz_GO_aff)
print(mwu_result)

mwu_result <- wilcox.test(hit_falsealarm ~ talkergroup_final, data = ZOO_FCz_Pz_NOGO_neut)
print(mwu_result)
mwu_result <- wilcox.test(hit_falsealarm ~ talkergroup_final, data = ZOO_FCz_Pz_NOGO_aff)
print(mwu_result)


model1 <- lmer(accuracy ~ talkergroup_final*Emotion*Condition + 
                 calculator_gender_cve + calculator_age_cve  + (1|Subject), data = ZOO_FCz_Pz, REML = TRUE)
anova(model1)
plot_model(model1, type="pred", terms = c("Emotion" , "Condition", "talkergroup_final"))  


```

# BEHAVIORAL ANALYSES - PREMATURE RESPONSES:
```{r}
# Premature Responses
mwu_result <- wilcox.test(premature_responses ~ talkergroup_final, data = ZOO_FCz_Pz_NOGO_neut)
print(mwu_result)
mwu_result <- wilcox.test(premature_responses ~ talkergroup_final, data = ZOO_FCz_Pz_NOGO_aff)
print(mwu_result)
mwu_result <- wilcox.test(premature_responses ~ talkergroup_final, data = ZOO_FCz_Pz_GO_neut)
print(mwu_result)
mwu_result <- wilcox.test(premature_responses ~ talkergroup_final, data = ZOO_FCz_Pz_GO_aff)
print(mwu_result)

model1 <- lmer(premature_responses ~ talkergroup_final*Emotion*Condition + 
                 calculator_gender_cve + calculator_age_cve  + (1|Subject), data = ZOO_FCz_Pz, REML = TRUE)
anova(model1)
plot_model(model1, type="pred", terms = c("Emotion" , "Condition", "talkergroup_final"))  

emmeans_result <- emmeans(model1, pairwise ~  talkergroup_final | Condition) # Tukey is default
pairs(emmeans_result, adjust= "none", simple = "each")   # adjust = "bonferroni"



model1 <- lmer(premature_responses ~ talkergroup_final*Emotion + 
                 calculator_gender_cve + calculator_age_cve  + (1|Subject), data = ZOO_FCz_Pz_GO, REML = TRUE)
anova(model1)
plot_model(model1, type="pred", terms = c("Emotion" , "talkergroup_final"))  

emmeans_result <- emmeans(model1, pairwise ~  talkergroup_final | Emotion) # Tukey is default
pairs(emmeans_result, adjust= "none", simple = "each")   # adjust = "bonferroni"



model1 <- lmer(premature_responses ~ talkergroup_final*Emotion + 
                 calculator_gender_cve + calculator_age_cve  + (1|Subject), data = ZOO_FCz_Pz_NOGO, REML = TRUE)
anova(model1)
plot_model(model1, type="pred", terms = c("Emotion" , "talkergroup_final"))  

emmeans_result <- emmeans(model1, pairwise ~  talkergroup_final | Emotion) # Tukey is default
pairs(emmeans_result, adjust= "none", simple = "each")   # adjust = "bonferroni"

```

# BEHAVIORAL ANALYSES - SENSITIVITY

```{r}
# Sensitivity - normally distributed
# Perform a two-sample t-test
t_test_result <- t.test(sensitivity ~ talkergroup_final,  data = ZOO_FCz_Pz_GO_neut, alternative = "two.sided")
print(t_test_result)
t_test_result <- t.test(sensitivity ~ talkergroup_final,  data = ZOO_FCz_Pz_GO_aff, alternative = "two.sided")
print(t_test_result)
# Lm with covariate, when age is taken into account sensitivity is significant <.05. 
lm_result <- lm(sensitivity ~ talkergroup_final + calculator_age_cve + calculator_gender_cve, data = ZOO_FCz_Pz_GO_neut)
summary(lm_result)
lm_result <- lm(sensitivity ~ talkergroup_final + calculator_age_cve + calculator_gender_cve, data = ZOO_FCz_Pz_GO_aff)
summary(lm_result)


#GLOBAL MODEL - SENSITIVITY
model1 <- lmer(sensitivity ~ talkergroup_final*Emotion + calculator_gender_cve + calculator_age_cve + (1| Subject), data = ZOO_FCz_Pz_NOGO)
anova(model1)
pairwise_comp <- emmeans(model1, pairwise ~  talkergroup_final | Emotion) # Tukey is default
pairs(pairwise_comp, adjust= "none", simple = "each")   # adjust = "bonferroni"

# Create a new model using aov()
model_aov <- aov(sensitivity ~ talkergroup_final * Emotion + calculator_gender_cve + calculator_age_cve, data = ZOO_FCz_Pz_NOGO)
summary(model_aov)


# check for assumptions:

# Linearity and Homoscedasticity:
# If the relationship is linear, there should be no pattern to the residuals
# The spread of the residuals should be constant across all levels of the fitted values.
# create residuals vs fitted values plot
plot(resid(model1) ~ fitted(model1), ylab="Residuals", xlab="Fitted values")
# add a regression line
abline(lm(resid(model1) ~ fitted(model1)), col="red")
#The Breusch-Pagan test or the White test can be used to statistically test for constant variance of the residuals (homoscedasticity)
library(lmtest)
bptest(residuals(model1) ~ fitted(model1))

# Normality: The points should fall along a straight line.
qqnorm(resid(model1))
qqline(resid(model1))
# a statistical test for normality, such as the Shapiro-Wilk test
shapiro.test(resid(model1))

# No multicollinearity: You can check this assumption by calculating the variance inflation factors (VIF) for the predictors. 
# A VIF greater than 5 or 10 indicates high multicollinearity.
library(car)
vif(model1)


```
# BEHAVIORAL ANALYSES - REACTION TIME:

```{r}

# Reaction Time - normally distributed
lm_result <- lm(RT_proper ~ talkergroup_final + calculator_age_cve + calculator_gender_cve, data = ZOO_FCz_Pz_GO_neut)
summary(lm_result)
lm_result <- lm(RT_proper ~ talkergroup_final + calculator_age_cve + calculator_gender_cve, data = ZOO_FCz_Pz_GO_aff)
summary(lm_result)
lm_result <- lm(RT_proper ~ talkergroup_final + calculator_age_cve + calculator_gender_cve, data = ZOO_FCz_Pz_NOGO_neut)
summary(lm_result)
lm_result <- lm(RT_proper ~ talkergroup_final + calculator_age_cve + calculator_gender_cve, data = ZOO_FCz_Pz_NOGO_aff)
summary(lm_result)


model1 <- lmer(RT_proper ~ talkergroup_final*Emotion*Condition + 
                 calculator_gender_cve + calculator_age_cve  + (1|Subject), data = ZOO_FCz_Pz, REML = TRUE)
anova(model1)
plot_model(model1, type="pred", terms = c("Emotion" , "talkergroup_final"))  


model1 <- lmer(RT_proper ~ talkergroup_final*Emotion + 
                 calculator_gender_cve + calculator_age_cve  + (1|Subject), data = ZOO_FCz_Pz_GO, REML = TRUE)
anova(model1)
plot_model(model1, type="pred", terms = c("Emotion" , "talkergroup_final"))  

model1 <- lmer(RT_proper ~ talkergroup_final*Emotion + 
                 calculator_gender_cve + calculator_age_cve  + (1|Subject), data = ZOO_FCz_Pz_NOGO, REML = TRUE)
anova(model1)
plot_model(model1, type="pred", terms = c("Emotion" , "talkergroup_final"))  


```

# BARPLOTS FOR BRIEF DATA:
```{r}


# Create the Dataframe to get the brief data

summary_brief_x <- 
  ZOO_FCz_Pz%>%
  group_by(Subject) %>%
  filter(!is.na(inhibit)) %>%
  summarise(
    age = mean(calculator_age_cve, na.rm = TRUE),
    talkergroup_final = mean(talkergroup_final, na.rm = TRUE),
    inhibit = mean(inhibit, na.rm = TRUE),
    shift = mean(shift, na.rm = TRUE),
    emotionalCntrl = mean(emotionalCntrl, na.rm = TRUE),
    workingMemory = mean(workingMemory, na.rm = TRUE),
    planOrganize = mean(planOrganize, na.rm = TRUE),
    BehavioralRegulationIndex_BRI = mean(BehavioralRegulationIndex_BRI, na.rm = TRUE),
    MetacognitionIndex_MI = mean(MetacognitionIndex_MI, na.rm = TRUE),
    GlobalExecutiveComposite_GEC = mean(GlobalExecutiveComposite_GEC, na.rm = TRUE)
    )

summary_brief <- 
  summary_brief_x%>%
  group_by(talkergroup_final) %>%
  summarise(
    age_mean = mean(age, na.rm = TRUE),
    inhibit_mean = mean(inhibit, na.rm = TRUE),
    SEM_inhibit_mean= sd(inhibit, na.rm = TRUE) / sqrt(n()),
    shift_mean = mean(shift, na.rm = TRUE),
    SEM_shift_mean = sd(shift, na.rm = TRUE) / sqrt(n()),
    emotionalCntrl_mean = mean(emotionalCntrl, na.rm = TRUE),
    SEM_emotionalCntrl_mean = sd(emotionalCntrl, na.rm = TRUE) / sqrt(n()),
    workingMemory_mean = mean(workingMemory, na.rm = TRUE),
    SEM_workingMemory_mean = sd(workingMemory, na.rm = TRUE) / sqrt(n()),
    planOrganize_mean = mean(planOrganize, na.rm = TRUE),
    SEM_planOrganize_mean = sd(planOrganize, na.rm = TRUE) / sqrt(n()),
    BehavioralRegulationIndex_BRI_mean = mean(BehavioralRegulationIndex_BRI, na.rm = TRUE),
    SEM_BehavioralRegulationIndex_BRI_mean = sd(BehavioralRegulationIndex_BRI, na.rm = TRUE) / sqrt(n()),
    MetacognitionIndex_MI_mean = mean(MetacognitionIndex_MI, na.rm = TRUE),
    SEM_MetacognitionIndex_MI_mean = sd(MetacognitionIndex_MI, na.rm = TRUE) / sqrt(n()),
    GlobalExecutiveComposite_GEC_mean = mean(GlobalExecutiveComposite_GEC, na.rm = TRUE),
    SEM_GlobalExecutiveComposite_GEC_mean = sd(GlobalExecutiveComposite_GEC, na.rm = TRUE) / sqrt(n())
    )

summary_brief_young <- 
  summary_brief_x%>%
  filter(age < 55 ) %>%
  group_by(talkergroup_final) %>%
  summarise(
    age_mean = mean(age, na.rm = TRUE),
    inhibit_mean = mean(inhibit, na.rm = TRUE),
    SEM_inhibit_mean= sd(inhibit, na.rm = TRUE) / sqrt(n()),
    shift_mean = mean(shift, na.rm = TRUE),
    SEM_shift_mean = sd(shift, na.rm = TRUE) / sqrt(n()),
    emotionalCntrl_mean = mean(emotionalCntrl, na.rm = TRUE),
    SEM_emotionalCntrl_mean = sd(emotionalCntrl, na.rm = TRUE) / sqrt(n()),
    workingMemory_mean = mean(workingMemory, na.rm = TRUE),
    SEM_workingMemory_mean = sd(workingMemory, na.rm = TRUE) / sqrt(n()),
    planOrganize_mean = mean(planOrganize, na.rm = TRUE),
    SEM_planOrganize_mean = sd(planOrganize, na.rm = TRUE) / sqrt(n()),
    BehavioralRegulationIndex_BRI_mean = mean(BehavioralRegulationIndex_BRI, na.rm = TRUE),
    SEM_BehavioralRegulationIndex_BRI_mean = sd(BehavioralRegulationIndex_BRI, na.rm = TRUE) / sqrt(n()),
    MetacognitionIndex_MI_mean = mean(MetacognitionIndex_MI, na.rm = TRUE),
    SEM_MetacognitionIndex_MI_mean = sd(MetacognitionIndex_MI, na.rm = TRUE) / sqrt(n()),
    GlobalExecutiveComposite_GEC_mean = mean(GlobalExecutiveComposite_GEC, na.rm = TRUE),
    SEM_GlobalExecutiveComposite_GEC_mean = sd(GlobalExecutiveComposite_GEC, na.rm = TRUE) / sqrt(n())
    )


summary_brief_old <- 
  summary_brief_x%>%
  filter(age > 55 ) %>%
  group_by(talkergroup_final) %>%
  summarise(
    age_mean = mean(age, na.rm = TRUE),
    inhibit_mean = mean(inhibit, na.rm = TRUE),
    SEM_inhibit_mean= sd(inhibit, na.rm = TRUE) / sqrt(n()),
    shift_mean = mean(shift, na.rm = TRUE),
    SEM_shift_mean = sd(shift, na.rm = TRUE) / sqrt(n()),
    emotionalCntrl_mean = mean(emotionalCntrl, na.rm = TRUE),
    SEM_emotionalCntrl_mean = sd(emotionalCntrl, na.rm = TRUE) / sqrt(n()),
    workingMemory_mean = mean(workingMemory, na.rm = TRUE),
    SEM_workingMemory_mean = sd(workingMemory, na.rm = TRUE) / sqrt(n()),
    planOrganize_mean = mean(planOrganize, na.rm = TRUE),
    SEM_planOrganize_mean = sd(planOrganize, na.rm = TRUE) / sqrt(n()),
    BehavioralRegulationIndex_BRI_mean = mean(BehavioralRegulationIndex_BRI, na.rm = TRUE),
    SEM_BehavioralRegulationIndex_BRI_mean = sd(BehavioralRegulationIndex_BRI, na.rm = TRUE) / sqrt(n()),
    MetacognitionIndex_MI_mean = mean(MetacognitionIndex_MI, na.rm = TRUE),
    SEM_MetacognitionIndex_MI_mean = sd(MetacognitionIndex_MI, na.rm = TRUE) / sqrt(n()),
    GlobalExecutiveComposite_GEC_mean = mean(GlobalExecutiveComposite_GEC, na.rm = TRUE),
    SEM_GlobalExecutiveComposite_GEC_mean = sd(GlobalExecutiveComposite_GEC, na.rm = TRUE) / sqrt(n())
    )

# Rename some factors for better visuals:
summary_brief$talkergroup_final <- factor(summary_brief$talkergroup_final, levels = c(0, 1), labels = c("CWNS", "CWS"))
summary_brief_young$talkergroup_final <- factor(summary_brief_young$talkergroup_final, levels = c(0, 1), labels = c("CWNS", "CWS"))
summary_brief_old$talkergroup_final <- factor(summary_brief_old$talkergroup_final, levels = c(0, 1), labels = c("CWNS", "CWS"))


# BAR PLOTS

library(gridExtra)

bar_plot1 <- ggplot(summary_brief, aes(x = talkergroup_final, y = inhibit_mean)) +
  geom_bar(stat = "identity", position = "dodge",  width = 0.5, fill ='royalblue2') +
  geom_errorbar(aes(ymin = inhibit_mean - SEM_inhibit_mean, ymax = inhibit_mean + SEM_inhibit_mean), width = 0.2, position = position_dodge(width = 0.7)) +
  labs(x = "TalkerGroup", y = "Inhibit") +
  theme_minimal() 

bar_plot2 <- ggplot(summary_brief, aes(x = talkergroup_final, y = shift_mean)) +
  geom_bar(stat = "identity", position = "dodge",  width = 0.5, fill ='royalblue2') +
  geom_errorbar(aes(ymin = shift_mean - SEM_shift_mean, ymax = shift_mean + SEM_shift_mean), width = 0.2, position = position_dodge(width = 0.7)) +
  labs(x = "TalkerGroup", y = "shift") +
  theme_minimal() 

bar_plot3 <- ggplot(summary_brief, aes(x = talkergroup_final, y = emotionalCntrl_mean)) +
  geom_bar(stat = "identity", position = "dodge",  width = 0.5, fill ='royalblue2') +
  geom_errorbar(aes(ymin = emotionalCntrl_mean - SEM_emotionalCntrl_mean, ymax = emotionalCntrl_mean + SEM_emotionalCntrl_mean), width = 0.2, position = position_dodge(width = 0.7)) +
  labs(x = "TalkerGroup", y = "emotionalCntrl") +
  theme_minimal() 

bar_plot4 <- ggplot(summary_brief, aes(x = talkergroup_final, y = workingMemory_mean)) +
  geom_bar(stat = "identity", position = "dodge",  width = 0.5, fill ='royalblue2') +
  geom_errorbar(aes(ymin = workingMemory_mean - SEM_workingMemory_mean, ymax = workingMemory_mean + SEM_workingMemory_mean), width = 0.2, position = position_dodge(width = 0.7)) +
  labs(x = "TalkerGroup", y = "workingMemory") +
  theme_minimal() 

bar_plot5 <- ggplot(summary_brief, aes(x = talkergroup_final, y = planOrganize_mean)) +
  geom_bar(stat = "identity", position = "dodge",  width = 0.5, fill ='royalblue2') +
  geom_errorbar(aes(ymin = planOrganize_mean - SEM_planOrganize_mean, ymax = planOrganize_mean + SEM_planOrganize_mean), width = 0.2, position = position_dodge(width = 0.7)) +
  labs(x = "TalkerGroup", y = "planOrganize") +
  theme_minimal() 

bar_plot6 <- ggplot(summary_brief, aes(x = talkergroup_final, y = BehavioralRegulationIndex_BRI_mean)) +
  geom_bar(stat = "identity", position = "dodge",  width = 0.5, fill ='royalblue2') +
  geom_errorbar(aes(ymin = BehavioralRegulationIndex_BRI_mean - SEM_BehavioralRegulationIndex_BRI_mean, ymax = BehavioralRegulationIndex_BRI_mean + SEM_BehavioralRegulationIndex_BRI_mean), width = 0.2, position = position_dodge(width = 0.7)) +
  labs(x = "TalkerGroup", y = "BehavioralRegulationIndex") +
  theme_minimal() 

bar_plot7 <- ggplot(summary_brief, aes(x = talkergroup_final, y = MetacognitionIndex_MI_mean)) +
  geom_bar(stat = "identity", position = "dodge",  width = 0.5, fill ='royalblue2') +
  geom_errorbar(aes(ymin = MetacognitionIndex_MI_mean - SEM_MetacognitionIndex_MI_mean, ymax = MetacognitionIndex_MI_mean + SEM_MetacognitionIndex_MI_mean), width = 0.2, position = position_dodge(width = 0.7)) +
  labs(x = "TalkerGroup", y = "MetacognitionIndex") +
  theme_minimal() 

bar_plot8 <- ggplot(summary_brief, aes(x = talkergroup_final, y = GlobalExecutiveComposite_GEC_mean)) +
  geom_bar(stat = "identity", position = "dodge",  width = 0.5, fill ='royalblue2') +
  geom_errorbar(aes(ymin = GlobalExecutiveComposite_GEC_mean - SEM_GlobalExecutiveComposite_GEC_mean, ymax = GlobalExecutiveComposite_GEC_mean + SEM_GlobalExecutiveComposite_GEC_mean), width = 0.2, position = position_dodge(width = 0.7)) +
  labs(x = "TalkerGroup", y = "GlobalExecutiveComposite") +
  theme_minimal() 

# arrange the plots in a grid
grid.arrange(bar_plot1, bar_plot2, bar_plot3, bar_plot4, bar_plot5, bar_plot6, bar_plot7, bar_plot8, ncol = 4, nrow = 2)


```

# BRIEF younger versus older ages

```{r}
bar_plot1 <- ggplot(summary_brief_young, aes(x = talkergroup_final, y = inhibit_mean)) +
  geom_bar(stat = "identity", position = "dodge",  width = 0.5, fill ='royalblue2') +
  geom_errorbar(aes(ymin = inhibit_mean - SEM_inhibit_mean, ymax = inhibit_mean + SEM_inhibit_mean), width = 0.2, position = position_dodge(width = 0.7)) +
  labs(x = "TalkerGroup", y = "Inhibit") +
  theme_minimal() + coord_cartesian(ylim = c(0, 30))

bar_plot2 <- ggplot(summary_brief_young, aes(x = talkergroup_final, y = shift_mean)) +
  geom_bar(stat = "identity", position = "dodge",  width = 0.5, fill ='royalblue2') +
  geom_errorbar(aes(ymin = shift_mean - SEM_shift_mean, ymax = shift_mean + SEM_shift_mean), width = 0.2, position = position_dodge(width = 0.7)) +
  labs(x = "TalkerGroup", y = "shift") +
  theme_minimal() + coord_cartesian(ylim = c(0, 15))

bar_plot3 <- ggplot(summary_brief_young, aes(x = talkergroup_final, y = emotionalCntrl_mean)) +
  geom_bar(stat = "identity", position = "dodge",  width = 0.5, fill ='royalblue2') +
  geom_errorbar(aes(ymin = emotionalCntrl_mean - SEM_emotionalCntrl_mean, ymax = emotionalCntrl_mean + SEM_emotionalCntrl_mean), width = 0.2, position = position_dodge(width = 0.7)) +
  labs(x = "TalkerGroup", y = "emotionalCntrl") +
  theme_minimal() + coord_cartesian(ylim = c(0, 20))

bar_plot4 <- ggplot(summary_brief_young, aes(x = talkergroup_final, y = workingMemory_mean)) +
  geom_bar(stat = "identity", position = "dodge",  width = 0.5, fill ='royalblue2') +
  geom_errorbar(aes(ymin = workingMemory_mean - SEM_workingMemory_mean, ymax = workingMemory_mean + SEM_workingMemory_mean), width = 0.2, position = position_dodge(width = 0.7)) +
  labs(x = "TalkerGroup", y = "workingMemory") +
  theme_minimal() + coord_cartesian(ylim = c(0, 25))

bar_plot5 <- ggplot(summary_brief_young, aes(x = talkergroup_final, y = planOrganize_mean)) +
  geom_bar(stat = "identity", position = "dodge",  width = 0.5, fill ='royalblue2') +
  geom_errorbar(aes(ymin = planOrganize_mean - SEM_planOrganize_mean, ymax = planOrganize_mean + SEM_planOrganize_mean), width = 0.2, position = position_dodge(width = 0.7)) +
  labs(x = "TalkerGroup", y = "planOrganize") +
  theme_minimal() + coord_cartesian(ylim = c(0, 20))

bar_plot6 <- ggplot(summary_brief_young, aes(x = talkergroup_final, y = BehavioralRegulationIndex_BRI_mean)) +
  geom_bar(stat = "identity", position = "dodge",  width = 0.5, fill ='royalblue2') +
  geom_errorbar(aes(ymin = BehavioralRegulationIndex_BRI_mean - SEM_BehavioralRegulationIndex_BRI_mean, ymax = BehavioralRegulationIndex_BRI_mean + SEM_BehavioralRegulationIndex_BRI_mean), width = 0.2, position = position_dodge(width = 0.7)) +
  labs(x = "TalkerGroup", y = "BehavioralRegulationIndex") +
  theme_minimal() + coord_cartesian(ylim = c(0, 60))

bar_plot7 <- ggplot(summary_brief_young, aes(x = talkergroup_final, y = MetacognitionIndex_MI_mean)) +
  geom_bar(stat = "identity", position = "dodge",  width = 0.5, fill ='royalblue2') +
  geom_errorbar(aes(ymin = MetacognitionIndex_MI_mean - SEM_MetacognitionIndex_MI_mean, ymax = MetacognitionIndex_MI_mean + SEM_MetacognitionIndex_MI_mean), width = 0.2, position = position_dodge(width = 0.7)) +
  labs(x = "TalkerGroup", y = "MetacognitionIndex") +
  theme_minimal() + coord_cartesian(ylim = c(0, 70))

bar_plot8 <- ggplot(summary_brief_young, aes(x = talkergroup_final, y = GlobalExecutiveComposite_GEC_mean)) +
  geom_bar(stat = "identity", position = "dodge",  width = 0.5, fill ='royalblue2') +
  geom_errorbar(aes(ymin = GlobalExecutiveComposite_GEC_mean - SEM_GlobalExecutiveComposite_GEC_mean, ymax = GlobalExecutiveComposite_GEC_mean + SEM_GlobalExecutiveComposite_GEC_mean), width = 0.2, position = position_dodge(width = 0.7)) +
  labs(x = "TalkerGroup", y = "GlobalExecutiveComposite") +
  theme_minimal() + coord_cartesian(ylim = c(0, 120))

# arrange the plots in a grid
grid.arrange(bar_plot1, bar_plot2, bar_plot3, bar_plot4, bar_plot5, bar_plot6, bar_plot7, bar_plot8, ncol = 4, nrow = 2)


bar_plot1 <- ggplot(summary_brief_old, aes(x = talkergroup_final, y = inhibit_mean)) +
  geom_bar(stat = "identity", position = "dodge",  width = 0.5, fill ='royalblue2') +
  geom_errorbar(aes(ymin = inhibit_mean - SEM_inhibit_mean, ymax = inhibit_mean + SEM_inhibit_mean), width = 0.2, position = position_dodge(width = 0.7)) +
  labs(x = "TalkerGroup", y = "Inhibit") +
  theme_minimal() + coord_cartesian(ylim = c(0, 30))

bar_plot2 <- ggplot(summary_brief_old, aes(x = talkergroup_final, y = shift_mean)) +
  geom_bar(stat = "identity", position = "dodge",  width = 0.5, fill ='royalblue2') +
  geom_errorbar(aes(ymin = shift_mean - SEM_shift_mean, ymax = shift_mean + SEM_shift_mean), width = 0.2, position = position_dodge(width = 0.7)) +
  labs(x = "TalkerGroup", y = "shift") +
  theme_minimal() + coord_cartesian(ylim = c(0, 15))

bar_plot3 <- ggplot(summary_brief_old, aes(x = talkergroup_final, y = emotionalCntrl_mean)) +
  geom_bar(stat = "identity", position = "dodge",  width = 0.5, fill ='royalblue2') +
  geom_errorbar(aes(ymin = emotionalCntrl_mean - SEM_emotionalCntrl_mean, ymax = emotionalCntrl_mean + SEM_emotionalCntrl_mean), width = 0.2, position = position_dodge(width = 0.7)) +
  labs(x = "TalkerGroup", y = "emotionalCntrl") +
  theme_minimal() + coord_cartesian(ylim = c(0, 20))

bar_plot4 <- ggplot(summary_brief_old, aes(x = talkergroup_final, y = workingMemory_mean)) +
  geom_bar(stat = "identity", position = "dodge",  width = 0.5, fill ='royalblue2') +
  geom_errorbar(aes(ymin = workingMemory_mean - SEM_workingMemory_mean, ymax = workingMemory_mean + SEM_workingMemory_mean), width = 0.2, position = position_dodge(width = 0.7)) +
  labs(x = "TalkerGroup", y = "workingMemory") +
  theme_minimal() + coord_cartesian(ylim = c(0, 25))

bar_plot5 <- ggplot(summary_brief_old, aes(x = talkergroup_final, y = planOrganize_mean)) +
  geom_bar(stat = "identity", position = "dodge",  width = 0.5, fill ='royalblue2') +
  geom_errorbar(aes(ymin = planOrganize_mean - SEM_planOrganize_mean, ymax = planOrganize_mean + SEM_planOrganize_mean), width = 0.2, position = position_dodge(width = 0.7)) +
  labs(x = "TalkerGroup", y = "planOrganize") +
  theme_minimal() + coord_cartesian(ylim = c(0, 20))

bar_plot6 <- ggplot(summary_brief_old, aes(x = talkergroup_final, y = BehavioralRegulationIndex_BRI_mean)) +
  geom_bar(stat = "identity", position = "dodge",  width = 0.5, fill ='royalblue2') +
  geom_errorbar(aes(ymin = BehavioralRegulationIndex_BRI_mean - SEM_BehavioralRegulationIndex_BRI_mean, ymax = BehavioralRegulationIndex_BRI_mean + SEM_BehavioralRegulationIndex_BRI_mean), width = 0.2, position = position_dodge(width = 0.7)) +
  labs(x = "TalkerGroup", y = "BehavioralRegulationIndex") +
  theme_minimal() + coord_cartesian(ylim = c(0, 60))

bar_plot7 <- ggplot(summary_brief_old, aes(x = talkergroup_final, y = MetacognitionIndex_MI_mean)) +
  geom_bar(stat = "identity", position = "dodge",  width = 0.5, fill ='royalblue2') +
  geom_errorbar(aes(ymin = MetacognitionIndex_MI_mean - SEM_MetacognitionIndex_MI_mean, ymax = MetacognitionIndex_MI_mean + SEM_MetacognitionIndex_MI_mean), width = 0.2, position = position_dodge(width = 0.7)) +
  labs(x = "TalkerGroup", y = "MetacognitionIndex") +
  theme_minimal() + coord_cartesian(ylim = c(0, 70))

bar_plot8 <- ggplot(summary_brief_old, aes(x = talkergroup_final, y = GlobalExecutiveComposite_GEC_mean)) +
  geom_bar(stat = "identity", position = "dodge",  width = 0.5, fill ='royalblue2') +
  geom_errorbar(aes(ymin = GlobalExecutiveComposite_GEC_mean - SEM_GlobalExecutiveComposite_GEC_mean, ymax = GlobalExecutiveComposite_GEC_mean + SEM_GlobalExecutiveComposite_GEC_mean), width = 0.2, position = position_dodge(width = 0.7)) +
  labs(x = "TalkerGroup", y = "GlobalExecutiveComposite") +
  theme_minimal() + coord_cartesian(ylim = c(0, 120))


# arrange the plots in a grid
grid.arrange(bar_plot1, bar_plot2, bar_plot3, bar_plot4, bar_plot5, bar_plot6, bar_plot7, bar_plot8, ncol = 4, nrow = 2)


```
# ERP MEASURES:

# P2 is an event-related potential (ERP) component in electroencephalography (EEG) studies. It is a positive-going wave that occurs approximately 200 milliseconds (ms) after the onset of a stimulus. In the context of a Go/NoGo task, the P2 component is often associated with early attentional processing of the stimuli. Studies have shown that the amplitude of the P2 component can be larger for NoGo trials compared to Go trials, indicating that more attentional resources are allocated to the process of inhibiting a response.

# N2 ERP component is a negative-going event-related potential that is typically observed in a time window approximately 200-350 ms after the onset of a stimulus. It is generally linked with conflict monitoring, error detection, and response inhibition processes in cognitive control tasks. It is also often seen in tasks that require the detection of rare or unexpected events, hence it is sometimes referred to as the "mismatch negativity" or "surprise" signal.

```{r}

# ANOVA without random subject
model1 <- aov(MeanAmp_N2P2 ~ (talkergroup_final*Emotion*Condition) + calculator_gender_cve + calculator_age_cve + Error(Subject/(Emotion*Condition)), data = ZOO_FCz_Pz)
summary(model1)

# By including `(1|Subject)` in our model, we are taking into account the repeated measures nature of the `Condition` and `Emotion` variables.
model1 <- lmer(MeanAmp_N2P2 ~ talkergroup_final*Emotion*Condition  + calculator_gender_cve + calculator_age_cve +
                 (1|Subject), data = ZOO_FCz_Pz, REML = TRUE) 
anova(model1)

# This model allows for individual differences in the overall level of accuracy (Subject random intercept) and individual differences in the relationship between talkergroup_final and accuracy (Subject random slope for talkergroup_final).
model2 <- lmer(MeanAmp_N2P2 ~ talkergroup_final*Emotion*Condition  + calculator_gender_cve + calculator_age_cve +
                (1 + talkergroup_final | Subject), data = ZOO_FCz_Pz, REML = TRUE) 
anova(model2)


# More complex MODEL with an overall intercept (1), random slopes for Emotion and Condition, and these random effects vary by Subject:
model3 <- lmer(MeanAmp_N2P2 ~ (talkergroup_final*Emotion*Condition) + calculator_gender_cve + calculator_age_cve + (1+Emotion+Condition|Subject), data = ZOO_FCz_Pz, REML = TRUE)
anova(model3) 

# MODEL 1 IS PREFERRED OVER MODEL 2:

# Calculate AIC for model1
aic_model1 <- AIC(model1)
# Calculate AIC for model2
aic_model2 <- AIC(model2)
# Compare AIC values
if (aic_model1 < aic_model2) {
  cat("Model 1 is preferred (lower AIC)\n")
} else if (aic_model2 < aic_model1) {
  cat("Model 2 is preferred (lower AIC)\n")
} else {
  cat("Both models have similar AIC\n")
}


# check for assumptions:
# Check the residuals of your chosen model to ensure they are normally distributed and homoscedastic. If they are not, you may need to consider transformations of your dependent variable or a different type of model.

# Linearity and Homoscedasticity:
# If the relationship is linear, there should be no pattern to the residuals. The spread of the residuals should be constant across all levels of the fitted values.
# create residuals vs fitted values plot
plot(resid(model1) ~ fitted(model1), ylab="Residuals", xlab="Fitted values")
# add a regression line
abline(lm(resid(model1) ~ fitted(model1)), col="red")
#The Breusch-Pagan test or the White test can be used to statistically test for constant variance of the residuals (homoscedasticity)
library(lmtest)
bptest(residuals(model1) ~ fitted(model1))

# Normality: The points should fall along a straight line.
qqnorm(resid(model1))
qqline(resid(model1))
# Statistical test for normality, such as the Shapiro-Wilk test
shapiro.test(resid(model1))

# No multicollinearity: You can check this assumption by calculating the variance inflation factors (VIF) for the predictors. 
# A VIF greater than 5 or 10 indicates high multicollinearity.
library(car)
vif(model1)


# Plot model:
plot_model(model1, type="pred", terms = c("Emotion" , "Condition", "talkergroup_final")) 

# Calculate pairwise comparisons
emmeans_resulttalkergroupCondEmo <- emmeans(model1, pairwise ~ talkergroup_final|Condition|Emotion) 
emmeans_resulttalkergroupCondEmo
pairs(emmeans_resulttalkergroupCondEmo, adjust = "none", simple = "each") # ,adjust = "bonferroni")

# Calculate marginal means for the three-way interaction
means <- as.data.frame(emmeans(model1, specs = ~ talkergroup_final:Emotion:Condition))

# Rename the levels of the "talkergroup_final" and "Emotion" factors
means$talkergroup_final <- factor(means$talkergroup_final, levels = c(0, 1), labels = c("CWNS", "CWS"))
means$Emotion <- factor(means$Emotion, levels = c("Neg", "Neut"), labels = c("Affective", "Neutral"))

# Draw a bar graph using the model predicted values. 
bar_plot <-  ggplot(means, aes(x = Emotion, y = emmean, fill = Condition)) +
  geom_bar(stat = "identity", position = "dodge") +
  geom_errorbar(aes(ymin = emmean - SE, ymax = emmean + SE), width = 0.2, position = position_dodge(0.9)) +
  labs(x = "Emotion", y = "Mean N2-P2 in V") +
  facet_grid(. ~ talkergroup_final) +
  theme_minimal() +
  theme(
    axis.text = element_text(size = 14, color = "black"),
    axis.title = element_text(size = 14),
    legend.title =element_blank(),
    legend.text = element_text(size = 14),
    plot.title = element_text(hjust = 0.5, size = 14, face = "bold", vjust = 2),
    strip.text = element_text(size = 14, face = "bold")) + 
scale_fill_manual(values = c("royalblue2", "orangered", "royalblue2", "orangered", "royalblue2", "orangered", "royalblue2", "orangered"))

print(bar_plot)

```
# N2P2 - LATERALITY INCLUDED - EXPLORATION

```{r}

# LATERALITY INCLUDED (MAIN EFFECT OF EMOTION)
model1 <- lmer(MeanAmp_N2P2 ~ talkergroup_final*Emotion*Condition*Laterality + calculator_gender_cve + calculator_age_cve + 
                 (1|Subject), data = ZOO_good, REML = TRUE) 
anova(model1)
plot_model(model1, type="pred", terms = c("Emotion" , "Condition", "talkergroup_final")) 
plot_model(model1, type="pred", terms = c("Laterality")) 
plot_model(model1, type="pred", terms = c("Emotion")) 

# TAKING PREMATURE RESPONSES INTO ACCOUNT, EMOTION BECOMES SIGNIFICANT
model1 <- lmer(MeanAmp_N2P2 ~ talkergroup_final*Emotion*Condition*premature_responses + calculator_gender_cve + calculator_age_cve  +
                 (1|Subject), data = ZOO_FCz_Pz, REML = TRUE) #by including `(1|Subject)` in your model, you are taking into account the repeated measures nature of the `Condition` and `Emotion` variables.
anova(model1)
summary(model1)
plot_model(model1, type="pred", terms = c("Emotion" , "Condition", "talkergroup_final")) 
plot_model(model1, type="pred", terms = c("premature_responses" , "Emotion", "talkergroup_final")) 

# GLOBAL MODEL? EMOTION BECOMES SIGNIFICANT
model1 <- lmer(MeanAmp_N2P2 ~ talkergroup_final*Emotion*Condition + calculator_gender_cve + calculator_age_cve +   shift + inhibit + workingMemory + planOrganize + FlexibilityIndex_FI + InhibitorySelfControlIndex_ISCI + GlobalExecutiveComposite_GEC + disfluency_sldper100words + emotionalCntrl + BehavioralRegulationIndex_BRI + MetacognitionIndex_MI + premature_responses + RT_proper + sensitivity + (1|Subject), data = ZOO_FCz_Pz, REML = TRUE) 
anova(model1)
plot_model(model1, type="pred", terms = c("Emotion" , "Condition", "talkergroup_final")) 


# RIGHT SIDE: (NO MAIN EFFECT OF EMOTION)
ZOO_good_rightside <- subset(ZOO_good, Laterality == "Right")
  
model1 <- lmer(MeanAmp_N2P2 ~ talkergroup_final*Emotion*Condition + calculator_gender_cve + calculator_age_cve + 
                 (1|Subject), data = ZOO_good_rightside, REML = TRUE) 
anova(model1)
plot_model(model1, type="pred", terms = c("Emotion" , "Condition", "talkergroup_final")) 
plot_model(model1, type="pred", terms = c("Emotion")) 


# LEFT SIDE: (MAIN EFFECT OF EMOTION)
ZOO_good_leftside <- subset(ZOO_good, Laterality == "Left")
  
model1 <- lmer(MeanAmp_N2P2 ~ talkergroup_final*Emotion*Condition + calculator_gender_cve + calculator_age_cve + 
                 (1|Subject), data = ZOO_good_leftside, REML = TRUE) 
anova(model1)
plot_model(model1, type="pred", terms = c("Emotion" , "Condition", "talkergroup_final")) 
plot_model(model1, type="pred", terms = c("Emotion")) 

```
# P3 (or P300) component is a positive-going event-related potential (ERP) in electroencephalography (EEG) that typically occurs around 300 milliseconds (ms) after the onset of a stimulus, hence the name P300.

# In the context of a Go/NoGo task, P3 is often associated with cognitive processing involved in decision making and response execution or inhibition. More specifically:

# 1. P3a: This component is thought to reflect attention-related processes and is typically elicited by infrequent and unexpected stimuli, including NoGo stimuli in a Go/NoGo task. It is usually observed at frontal and central electrode sites.
# 2. P3b: This component is usually elicited by target stimuli in tasks that require a response, such as the Go stimuli in a Go/NoGo task. It is typically observed at parietal electrode sites and is thought to reflect processes related to memory updating and context closure.

# The P3 (P300) component is often associated with cognitive processes such as attention, decision making, and response execution or inhibition. In a Go/NoGo task, the NoGo trials require more cognitive resources as the participant must inhibit a prepotent response. This cognitive demand often results in a larger P3 component for NoGo trials.

# However, it's important to note that the specifics can vary depending on the individual and the exact design of the task. For instance, if the NoGo trials are very infrequent, the P3 amplitude might also be influenced by the novelty or surprise of these trials.


```{r}
# MAIN MODEL: only effect of condition
model1 <- lmer(MeanAmp_P3 ~ talkergroup_final*Emotion*Condition + calculator_gender_cve + calculator_age_cve + 
                 (1|Subject), data = ZOO_FCz_Pz, REML = TRUE) 
anova(model1)
plot_model(model1, type="pred", terms = c("Emotion" , "Condition", "talkergroup_final")) 


# GLOBAL MODEL: NOT MUCH CHANGES
model2 <- lmer(MeanAmp_P3 ~ talkergroup_final*Emotion*Condition + calculator_gender_cve + calculator_age_cve +  shift + inhibit +
                 workingMemory + planOrganize + FlexibilityIndex_FI + InhibitorySelfControlIndex_ISCI + GlobalExecutiveComposite_GEC +
                 disfluency_sldper100words + emotionalCntrl + BehavioralRegulationIndex_BRI + MetacognitionIndex_MI + premature_responses +
                 RT_proper + sensitivity + (1|Subject), data = ZOO_FCz_Pz, REML = TRUE) 
anova(model2)

# MODEL 2 IS PREFERRED OVER MODEL 1:

# Calculate AIC for model1
aic_model1 <- AIC(model1)
# Calculate AIC for model2
aic_model2 <- AIC(model2)
# Compare AIC values
if (aic_model1 < aic_model2) {
  cat("Model 1 is preferred (lower AIC)\n")
} else if (aic_model2 < aic_model1) {
  cat("Model 2 is preferred (lower AIC)\n")
} else {
  cat("Both models have similar AIC\n")
}


# Linearity and Homoscedasticity:
# If the relationship is linear, there should be no pattern to the residuals. The spread of the residuals should be constant across all levels of the fitted values.
# create residuals vs fitted values plot
plot(resid(model1) ~ fitted(model1), ylab="Residuals", xlab="Fitted values")
# add a regression line
abline(lm(resid(model1) ~ fitted(model1)), col="red")
#The Breusch-Pagan test or the White test can be used to statistically test for constant variance of the residuals (homoscedasticity)
library(lmtest)
bptest(residuals(model1) ~ fitted(model1))

# Normality: The points should fall along a straight line.
qqnorm(resid(model1))
qqline(resid(model1))
# Statistical test for normality, such as the Shapiro-Wilk test
shapiro.test(resid(model1))

# No multicollinearity: You can check this assumption by calculating the variance inflation factors (VIF) for the predictors. 
# A VIF greater than 5 or 10 indicates high multicollinearity.
library(car)
vif(model1)


# PLOT MODEL as if the three-way interaction exists
plot_model(model1, type="pred", terms = c("Emotion" , "Condition", "talkergroup_final")) 

# Calculate marginal means for NONEXISTENT the three-way interaction
means <- as.data.frame(emmeans(model1, specs = ~ talkergroup_final:Emotion:Condition))

# Rename the levels of the "talkergroup_final" factor
means$talkergroup_final <- factor(means$talkergroup_final, levels = c(0, 1), labels = c("CWNS", "CWS"))
means$Emotion <- factor(means$Emotion, levels = c("Neg", "Neut"), labels = c("Affective", "Neutral"))

# Plot the predicted means
bar_plot <-  ggplot(means, aes(x = Emotion, y = emmean, fill = Condition)) +
  geom_bar(stat = "identity", position = "dodge") +
  geom_errorbar(aes(ymin = emmean - SE, ymax = emmean + SE), width = 0.2, position = position_dodge(0.9)) +
  labs(x = "Emotion", y = "Mean P3 in V") +
  facet_grid(. ~ talkergroup_final) +
  theme_minimal() +
  theme(
    axis.text = element_text(size = 14, color = "black"),
    axis.title = element_text(size = 14),
    legend.title =element_blank(),
    legend.text = element_text(size = 14),
    plot.title = element_text(hjust = 0.5, size = 14, face = "bold", vjust = 2),
    strip.text = element_text(size = 14, face = "bold")) + 
scale_fill_manual(values = c("royalblue2", "orangered", "royalblue2", "orangered", "royalblue2", "orangered", "royalblue2", "orangered"))

bar_plot <- bar_plot + coord_cartesian(ylim = c(4, 12))
print(bar_plot)

bar_plot <-  ggplot(means, aes(x = Condition, y = emmean, fill = Emotion)) +
  geom_bar(stat = "identity", position = "dodge") +
  geom_errorbar(aes(ymin = emmean - SE, ymax = emmean + SE), width = 0.2, position = position_dodge(0.9)) +
  labs(x = "Condition", y = "Mean P3 in V") +
  facet_grid(. ~ talkergroup_final) +
  theme_minimal() +
  theme(
    axis.text = element_text(size = 14, color = "black"),
    axis.title = element_text(size = 14),
    legend.title =element_blank(),
    legend.text = element_text(size = 14),
    plot.title = element_text(hjust = 0.5, size = 14, face = "bold", vjust = 2),
    strip.text = element_text(size = 14, face = "bold")) + 
scale_fill_manual(values = c("springgreen3", "royalblue2", "springgreen3", "royalblue2", "springgreen3", "royalblue2", "springgreen3", "royalblue2")) 
bar_plot <- bar_plot + coord_cartesian(ylim = c(4, 12))
print(bar_plot)


```

# Other graphs - The code chunk is NOT evaluated and NO OUTPUT exits. 
# {r, eval=FALSE, include=FALSE}

```{r, eval=FALSE, include=FALSE}

# GO CONDITION ONLY!  
ZOO_FCz_Pz_GO <- subset(ZOO_FCz_Pz, Condition == "Go")
model1 <- lmer(MeanAmp_P3 ~ talkergroup_final*Emotion  + calculator_age_cve + calculator_gender_cve +   
                 (1|Subject), data = ZOO_FCz_Pz_GO, REML = TRUE)
anova(model1)

# Calculate marginal means for the three-way interaction
means <- as.data.frame(emmeans(model1, specs = ~ talkergroup_final:Emotion))
# filtered_means <- means[means$Condition == "Go", ] # keep all columns

means$talkergroup_final <- factor(means$talkergroup_final, levels = c(0, 1), labels = c("CWNS", "CWS"))
means$Emotion <- factor(means$Emotion, levels = c("Neg", "Neut"), labels = c("Affective", "Neutral"))

bar_plot <-  ggplot(means, aes(x = Emotion, y = emmean)) +
  geom_bar(stat = "identity", position = "dodge") +
  geom_errorbar(aes(ymin = emmean - SE, ymax = emmean + SE), width = 0.2, position = position_dodge(0.9)) +
  labs(x = "Emotion", y = "Mean P3 in V") +
  facet_grid(. ~ talkergroup_final) +
  theme_minimal() +
  theme(
    axis.text = element_text(size = 14, color = "black"),
    axis.title = element_text(size = 14),
    legend.title =element_blank(),
    legend.text = element_text(size = 14),
    plot.title = element_text(hjust = 0.5, size = 14, face = "bold", vjust = 2),
    strip.text = element_text(size = 14, face = "bold")) +
scale_fill_manual(values = c("springgreen3", "royalblue2", "springgreen3", "royalblue2"))

print(bar_plot)

```

# P3 LATERALITY INCLUDED  - EXPLORATION

```{r}

# LATERALITY -  LATERALITY TALKERGROUP INTERACTION
model1 <- lmer(MeanAmp_P3 ~ talkergroup_final*Emotion*Condition*Laterality + calculator_gender_cve + calculator_age_cve + 
                 (1|Subject), data = ZOO_good, REML = TRUE) 
anova(model1)
plot_model(model1, type="pred", terms = c("Laterality", "talkergroup_final")) 

```

# PREDICTING ACCURACY USING ERP MEASURES ACROSS ALL 4 CONDITIONS:

```{r}
# USED THIS FOR THE POSTER VKC - but not appropriate due to repeated nature of the design
# model1 <- lm (accuracy ~ talkergroup_final + MeanAmp_N2P2 + MeanAmp_P3 +MeanAmp_P2 + Latency_N2 + Latency_P3 + Latency_P2 + calculator_age_cve+calculator_gender_cve, data = ZOO_FCz_Pz)

# Given the repeated nature of your study (each subject having 4 accuracy scores), we should consider using a mixed-effects model to account for the potential correlation within the repeated measures:

# Random intercept for each subject
model1 <- lmer(accuracy ~ talkergroup_final*Emotion*Condition + MeanAmp_N2P2 + MeanAmp_P3 + MeanAmp_P2 + Latency_N2 + Latency_P3 +
                 Latency_P2 + calculator_age_cve + calculator_gender_cve +
               (1 | Subject), data = ZOO_FCz_Pz)
anova(model1)

# Random slope for talkergroup_final and a random intercept for each subject
model2 <- lmer(accuracy ~ talkergroup_final + MeanAmp_N2P2 + MeanAmp_P3 + MeanAmp_P2 + 
     Latency_N2 + Latency_P3 + Latency_P2 + calculator_age_cve + calculator_gender_cve +
     (1 + talkergroup_final | Subject), data = ZOO_FCz_Pz)
anova(model2)

# Much simpler model
# USE THIS BECAUSE WE DO NOT ANTICIPATE that talkergroup_final:Emotion:Condition interaction contributes to the variability in accuracy scores?
model3 <- lmer(accuracy ~ talkergroup_final + MeanAmp_N2P2 + MeanAmp_P3 + MeanAmp_P2 + Latency_N2 + Latency_P3 +
                 Latency_P2 + calculator_age_cve + calculator_gender_cve +
               (1 | Subject), data = ZOO_FCz_Pz)
anova(model3)

AIC(model1)
AIC(model2)
AIC(model3)
```

# PREDICTING SENSITIVITY USING ERP difference scores between Go and NOGO? 

```{r}


# FEATURE ENGINEER Go-NoGo difference score:

ZOO_FCz_Pz_DIFF <- ZOO_FCz_Pz %>%
  group_by(Subject, Emotion) %>%
  summarise(
    disfluency = disfluency_sldper100words_final[Condition == "Go"],
    talkergroup_final = talkergroup_final[Condition == "Go"],
    calculator_age_cve = calculator_age_cve[Condition == "Go"],
    calculator_gender_cve = calculator_gender_cve[Condition == "Go"],


    MeanAmp_N2P2_DIFF = MeanAmp_N2P2[Condition == "NoGo"] - MeanAmp_N2P2[Condition == "Go"],
    MeanAmp_P3_DIFF = MeanAmp_P3[Condition == "NoGo"] - MeanAmp_P3[Condition == "Go"],
    Latency_N2_DIFF = Latency_N2[Condition == "NoGo"] - Latency_N2[Condition == "Go"],
    Latency_P2_DIFF = Latency_P2[Condition == "NoGo"] - Latency_P3[Condition == "Go"],
    Latency_P3_DIFF = Latency_P3[Condition == "NoGo"] - Latency_P3[Condition == "Go"],
    
    premature_responses_DIFF = premature_responses[Condition == "NoGo"] - premature_responses[Condition == "Go"],
    RT_proper_DIFF = RT_proper[Condition == "NoGo"] - RT_proper[Condition == "Go"],
    sensitivity = sensitivity[Condition == "NoGo"],

    inhibit = inhibit[Condition == "Go"],
    shift = shift[Condition == "Go"],
    emotionalCntrl = emotionalCntrl[Condition == "Go"],
    workingMemory = workingMemory[Condition == "Go"],
    BehavioralRegulationIndex_BRI = BehavioralRegulationIndex_BRI[Condition == "Go"],
    MetacognitionIndex_MI = MetacognitionIndex_MI[Condition == "Go"],
    GlobalExecutiveComposite_GEC = GlobalExecutiveComposite_GEC[Condition == "Go"]
    )


# Sensitivity predicted by talkergroup, age, MetacognitionIndex_MI
model1 <- lmer(sensitivity ~ talkergroup_final*Emotion + MeanAmp_N2P2_DIFF + MeanAmp_P3_DIFF + Latency_N2_DIFF + Latency_P2_DIFF +
                 Latency_P3_DIFF + calculator_age_cve+calculator_gender_cve + inhibit +
                 shift + emotionalCntrl + workingMemory + BehavioralRegulationIndex_BRI + MetacognitionIndex_MI + GlobalExecutiveComposite_GEC + (1|Subject), data = ZOO_FCz_Pz_DIFF)
anova(model1)


# Sensitivity predicted by only talkergroup and age
model1 <- lmer(sensitivity ~ talkergroup_final*Emotion + MeanAmp_N2P2_DIFF + MeanAmp_P3_DIFF + Latency_N2_DIFF + Latency_P2_DIFF +
                 Latency_P3_DIFF + calculator_age_cve+calculator_gender_cve + (1|Subject), data = ZOO_FCz_Pz_DIFF)
anova(model1)

```

# PREDICTING ACCURACY USING ERP MEASURES - SCALED!

```{r}
#MODERATOR ANALYSIS WITH ALL CORTICAL MEASURES:

# Select columns from ZOO_FCz_Pz
selected_df <- dplyr::select(ZOO_FCz_Pz, Subject, talkergroup_final, accuracy, calculator_age_cve, calculator_gender_cve, Condition, Emotion, MeanAmp_N2P2, MeanAmp_N2, MeanAmp_P2, MeanAmp_P3, Latency_N2, Latency_P2, Latency_P3) 
# Converting Condition and Emotion into numerical variables:
selected_df$Condition <- as.integer(selected_df$Condition == "Go") # Go =1
selected_df$Emotion <- as.integer(selected_df$Emotion == "Neg") # Neg = 1

# Scaling the variables
# Specify the columns you want to scale
columns_to_scale <- c("MeanAmp_N2P2", "MeanAmp_N2", "MeanAmp_P2","MeanAmp_P3", "Latency_N2","Latency_P2", "Latency_P3", "calculator_age_cve")

# Subset the data frame to include only the columns you want to scale
selected_df_to_scale <- selected_df[, columns_to_scale]

# Scale the selected columns
selected_df_scaled <- as.data.frame(scale(selected_df_to_scale))

# Get the Unscaled columns + Subjects Column
# Because accuracy is the dependent measure no need to scale it!
selected_df_unscaled <- subset(selected_df, select = c( Subject, talkergroup_final, accuracy, calculator_gender_cve, Condition, Emotion))

# Combine the scaled subset with the original data frame
final_merged <- cbind(selected_df_scaled, selected_df_unscaled)


# MODEL 1
model1 <- lmer(accuracy ~ talkergroup_final*Condition*Emotion + MeanAmp_N2P2 + MeanAmp_P3 +MeanAmp_P2 + Latency_N2 + Latency_P3 +
                 Latency_P2 + calculator_age_cve  + (1|Subject),  data = final_merged)
anova(model1)
AIC(model1)

# MODEL 2
model2 <- lmer(accuracy ~ talkergroup_final + MeanAmp_N2P2 + MeanAmp_P3 +MeanAmp_P2 + Latency_N2 + Latency_P3 +
                 Latency_P2 + calculator_age_cve  + (1|Subject),  data = final_merged)
anova(model2)

plot1 <- plot_model(model1, type='pred', terms = c("MeanAmp_P3", "Emotion", "talkergroup_final"))  + aes(linetype = group, color = group) +
  theme_bw() +
  labs(x = "Mean P3 Amplitude (Scaled)",  y = "Accuracy (%)", fill = "talkergroup_final")+
  theme(axis.title.x = element_text(family="Arial", color = "grey20", size = 14, angle = 0),
        axis.title.y = element_text(family="Arial", color = "grey20", size = 14, angle = 90),
        axis.text.x = element_text(family="Arial", color = "grey20", size = 12, angle = 0),
        axis.text.y = element_text(family="Arial", color = "grey20", size = 12, angle = 0),
        legend.text = element_text(family="Arial", color = "grey20", size = 12, angle = 0),
        title = element_blank(),
        legend.title = element_blank())+
  scale_color_manual(values = c("mediumpurple1", "springgreen3"), labels = c("Neutral", "Affective")) +
  scale_fill_manual(values = c("mediumpurple1", "springgreen3"), labels = c("Neutral", "Affective")) 

print(plot1)
```



#FIT MULTIPLE LINEAR MODELS FOR EACH TALKERGROUP AND EMOTION
```{r}

# Create an empty data frame to store the results
results_df <- data.frame(
  Emotion = character(),
  TalkerGroup = character(),
  P_Value = numeric(),
  stringsAsFactors = FALSE
)

# Create a subset of your data for each combination of emotion and talkergroup
subsets <- final_merged %>%
  filter(Emotion %in% c(0,1), talkergroup_final %in% c(0, 1))

# Loop through each combination and extract the p-values
for (emotion in unique(subsets$Emotion)) {
  for (group in unique(subsets$talkergroup_final)) {
    subset_data <- subsets %>%
      filter(Emotion == emotion, talkergroup_final == group)
    
    # Fit a linear regression model for the current combination
    model <- lm(accuracy ~ MeanAmp_P3, data = subset_data)
    
    # Extract the p-value
    p_value <- summary(model)$coefficients[2, 4]  # Assumes MeanAmp_P3 is the second coefficient
    
    # Create a data frame with the results
    result_row <- data.frame(
      Emotion = emotion,
      TalkerGroup = paste("talkergroup", group),
      P_Value = p_value
    )
    
    # Append the results to the results data frame
    results_df <- rbind(results_df, result_row)
  }
}

# Print the results
print(results_df)


```


# CORRELATIONS BETWEEN ERPs and ACCURACY
```{r}

ZOO_Corr_DIFF_Neg_CWS <- subset(ZOO_FCz_Pz_DIFF, Emotion == "Neg" & talkergroup_final == 1)
ZOO_Corr_DIFF_Neg_CWNS <- subset(ZOO_FCz_Pz_DIFF, Emotion == "Neg" & talkergroup_final == 0)
ZOO_Corr_DIFF_Neut_CWS <- subset(ZOO_FCz_Pz_DIFF, Emotion == "Neut" & talkergroup_final == 1)
ZOO_Corr_DIFF_Neut_CWNS <- subset(ZOO_FCz_Pz_DIFF, Emotion == "Neut" & talkergroup_final == 0)

ZOO_Corr_NoGo_Neg_CWS <- subset(ZOO_FCz_Pz, Condition == "NoGo" & Emotion == "Neg" & talkergroup_final == 1)
ZOO_Corr_NoGo_Neut_CWS <- subset(ZOO_FCz_Pz, Condition == "NoGo" & Emotion == "Neut" & talkergroup_final == 1)
ZOO_Corr_Go_Neg_CWS <- subset(ZOO_FCz_Pz, Condition == "Go" & Emotion == "Neg" & talkergroup_final == 1)
ZOO_Corr_Go_Neut_CWS <- subset(ZOO_FCz_Pz, Condition == "Go" & Emotion == "Neut" & talkergroup_final == 1)

ZOO_Corr_NoGo_Neg_CWNS <- subset(ZOO_FCz_Pz, Condition == "NoGo" & Emotion == "Neg" & talkergroup_final == 0)
ZOO_Corr_NoGo_Neut_CWNS <- subset(ZOO_FCz_Pz, Condition == "NoGo" & Emotion == "Neut" & talkergroup_final == 0)
ZOO_Corr_Go_Neg_CWNS <- subset(ZOO_FCz_Pz, Condition == "Go" & Emotion == "Neg" & talkergroup_final == 0)
ZOO_Corr_Go_Neut_CWNS <- subset(ZOO_FCz_Pz, Condition == "Go" & Emotion == "Neut" & talkergroup_final == 0)


rownames(ZOO_Corr_DIFF_Neg_CWS) <- NULL
rownames(ZOO_Corr_DIFF_Neg_CWNS) <- NULL
rownames(ZOO_Corr_DIFF_Neut_CWS) <- NULL
rownames(ZOO_Corr_DIFF_Neut_CWNS) <- NULL
rownames(ZOO_Corr_NoGo_Neg_CWS) <- NULL
rownames(ZOO_Corr_NoGo_Neut_CWS) <- NULL
rownames(ZOO_Corr_Go_Neg_CWS) <- NULL
rownames(ZOO_Corr_Go_Neut_CWS) <- NULL
rownames(ZOO_Corr_NoGo_Neg_CWNS) <- NULL
rownames(ZOO_Corr_NoGo_Neut_CWNS) <- NULL
rownames(ZOO_Corr_Go_Neg_CWNS) <- NULL
rownames(ZOO_Corr_Go_Neut_CWNS) <- NULL

# Bind the datasets row-wise
ZOO_Corr_NoGo_CWS <- bind_rows(ZOO_Corr_NoGo_Neg_CWS, ZOO_Corr_NoGo_Neut_CWS)
# Group by variable and calculate the mean for each variable
ZOO_Corr_NoGo_CWS <- ZOO_Corr_NoGo_CWS %>%
  group_by(Subject) %>%
  summarise_all(mean)

# Bind the datasets row-wise
ZOO_Corr_NoGo_CWNS <- bind_rows(ZOO_Corr_NoGo_Neg_CWNS, ZOO_Corr_NoGo_Neut_CWNS)
# Group by variable and calculate the mean for each variable
ZOO_Corr_NoGo_CWNS <- ZOO_Corr_NoGo_CWNS %>%
  group_by(Subject) %>%
  summarise_all(mean)


#DRAW CORRELATION PLOTS###########################

correlation_analysis <- function(df1, df2, var1, var2) {

# Perform the correlation test
correlation_CWS <- cor.test(df1[[var1]], df1[[var2]], use="complete.obs") #exclude pairs with missing values
correlation_CWNS <- cor.test(df2[[var1]], df2[[var2]], use="complete.obs")

# Create a scatter plot with a regression line and confidence interval
# use `aes_string()` or aes with !!sym  when you're passing variable names as strings.

title <- paste(deparse(substitute(df1)), "and", deparse(substitute(df2)))

ggplot() +
geom_point(data = df1, aes(x = !!sym(var1), y = !!sym(var2)), color = "red") +
geom_smooth(data = df1, aes(x = !!sym(var1), y = !!sym(var2)), method = "lm", se = TRUE, col = "red") +
geom_point(data = df2, aes(x = !!sym(var1), y = !!sym(var2)), color = "blue") +
geom_smooth(data = df2, aes(x = !!sym(var1), y = !!sym(var2)), method = "lm", se = TRUE, col = "blue") +
labs(title = title, x = "ERP Amplitude (V)", y = "Accuracy (%)") +
theme_minimal() + # Set background to white
theme(panel.grid.major = element_blank(), # Remove major grid lines
panel.grid.minor = element_blank(), # Remove minor grid lines
axis.line = element_line(color = "black"),
axis.text = element_text(size = 14), # Increase font size for both axis labels and tick labels
axis.title = element_text(size = 16)) + # Increase font size for axis labels
# ylim(40, 110) + # Replace ymin_value and ymax_value with your desired limits
annotate("text", x = mean(df1[[var1]]), y = max(df1[[var2]]),
label = paste("CWS r =", round(correlation_CWS$estimate, 3)), col = "red") +
annotate("text", x = mean(df1[[var1]]), y = max(df1[[var2]]),
label = paste("p-value =", round(correlation_CWS$p.value, 3)),  vjust = -2,  col = "red") +
annotate("text", x = mean(df2[[var1]]), y = min(df2[[var2]]) ,
label = paste("CWNS r =", round(correlation_CWNS$estimate, 3)),  col = "blue") +
annotate("text", x = mean(df2[[var1]]), y = min(df2[[var2]]),
label = paste("p-value =", round(correlation_CWNS$p.value, 3)),  vjust = -2, col = "blue") +
theme(legend.position = "none")
}



correlation_analysis(ZOO_Corr_NoGo_Neg_CWS, ZOO_Corr_NoGo_Neg_CWNS, "MeanAmp_N2P2", "accuracy")
correlation_analysis(ZOO_Corr_NoGo_Neut_CWS, ZOO_Corr_NoGo_Neut_CWNS, "MeanAmp_N2P2", "accuracy")
correlation_analysis(ZOO_Corr_Go_Neg_CWS, ZOO_Corr_Go_Neg_CWNS, "MeanAmp_N2P2", "accuracy")
correlation_analysis(ZOO_Corr_Go_Neut_CWS, ZOO_Corr_Go_Neut_CWNS, "MeanAmp_N2P2", "accuracy")

correlation_analysis(ZOO_Corr_NoGo_Neg_CWS, ZOO_Corr_NoGo_Neg_CWNS, "MeanAmp_P3", "accuracy")
correlation_analysis(ZOO_Corr_NoGo_Neut_CWS, ZOO_Corr_NoGo_Neut_CWNS, "MeanAmp_P3", "accuracy")
correlation_analysis(ZOO_Corr_Go_Neg_CWS, ZOO_Corr_Go_Neg_CWNS, "MeanAmp_P3", "accuracy")
correlation_analysis(ZOO_Corr_Go_Neut_CWS, ZOO_Corr_Go_Neut_CWNS, "MeanAmp_P3", "accuracy")


#PERSONALIZED PLOT######
correlation_CWS_Neg_NOGO <- cor.test(ZOO_Corr_NoGo_Neg_CWS$MeanAmp_P3, ZOO_Corr_NoGo_Neg_CWS$accuracy)
correlation_CWNS_Neg_NOGO <- cor.test(ZOO_Corr_NoGo_Neg_CWNS$MeanAmp_P3, ZOO_Corr_NoGo_Neg_CWNS$accuracy)

# Create a scatter plot with a regression line and confidence interval
ggplot() +
geom_point(data = ZOO_Corr_NoGo_Neg_CWNS, aes(x = MeanAmp_P3, y = accuracy), color = "royalblue") +
geom_smooth(data = ZOO_Corr_NoGo_Neg_CWNS, aes(x = MeanAmp_P3, y = accuracy), method = "lm", se = TRUE, col = "royalblue") +
geom_point(data = ZOO_Corr_NoGo_Neg_CWS, aes(x = MeanAmp_P3, y = accuracy), color = "orangered") +
geom_smooth(data = ZOO_Corr_NoGo_Neg_CWS, aes(x = MeanAmp_P3, y = accuracy), method = "lm", se = TRUE, col = "orangered") +
labs(title = "CWNS in Affective GO and NOGO", x = "P3 Amplitude (V)", y = "Accuracy (%)") +
theme_minimal() + # Set background to white
theme(panel.grid.major = element_blank(), # Remove major grid lines
panel.grid.minor = element_blank(), # Remove minor grid lines
axis.line = element_line(color = "black"),
axis.text = element_text(size = 14), # Increase font size for both axis labels and tick labels
axis.title = element_text(size = 16)) + # Increase font size for axis labels
ylim(40, 110) + # Replace ymin_value and ymax_value with your desired limits
annotate("text", x = mean(ZOO_Corr_NoGo_Neg_CWNS$MeanAmp_P3), y = max(ZOO_Corr_NoGo_Neg_CWNS$accuracy) + 5,
label = paste("CWNS Affective NOGO r =", round(correlation_CWNS_Neg_NOGO$estimate, 3)), vjust = -1, col = "royalblue") +
annotate("text", x = mean(ZOO_Corr_NoGo_Neg_CWNS$MeanAmp_P3), y = max(ZOO_Corr_NoGo_Neg_CWNS$accuracy),
label = paste("p-value =", round(correlation_CWNS_Neg_NOGO$p.value, 3)), vjust = -1, col = "royalblue") +
annotate("text", x = mean(ZOO_Corr_NoGo_Neg_CWS$MeanAmp_P3), y = min(ZOO_Corr_NoGo_Neg_CWS$accuracy) + 5,
label = paste("CWS Affective NOGO r =", round(correlation_CWS_Neg_NOGO$estimate, 3)), vjust = -1, col = "orangered") +
annotate("text", x = mean(ZOO_Corr_NoGo_Neg_CWS$MeanAmp_P3), y = min(ZOO_Corr_NoGo_Neg_CWS$accuracy),
label = paste("p-value =", round(correlation_CWS_Neg_NOGO$p.value, 3)), vjust = -1, col = "orangered") +
theme(legend.position = "none")

```

# BRIEF SCORES CORRELATION

```{r}
correlation_analysis(ZOO_Corr_DIFF_Neut_CWS, ZOO_Corr_DIFF_Neut_CWNS, "MeanAmp_N2P2_DIFF", "sensitivity")
correlation_analysis(ZOO_Corr_DIFF_Neut_CWS, ZOO_Corr_DIFF_Neut_CWNS, "MeanAmp_N2P2_DIFF", "premature_responses_DIFF")
correlation_analysis(ZOO_Corr_DIFF_Neut_CWS, ZOO_Corr_DIFF_Neut_CWNS, "MeanAmp_N2P2_DIFF", "RT_proper_DIFF")
correlation_analysis(ZOO_Corr_DIFF_Neut_CWS, ZOO_Corr_DIFF_Neut_CWNS, "MeanAmp_N2P2_DIFF", "inhibit")
correlation_analysis(ZOO_Corr_DIFF_Neut_CWS, ZOO_Corr_DIFF_Neut_CWNS, "MeanAmp_N2P2_DIFF", "shift")
correlation_analysis(ZOO_Corr_DIFF_Neut_CWS, ZOO_Corr_DIFF_Neut_CWNS, "MeanAmp_N2P2_DIFF", "workingMemory")
correlation_analysis(ZOO_Corr_DIFF_Neut_CWS, ZOO_Corr_DIFF_Neut_CWNS, "MeanAmp_N2P2_DIFF", "BehavioralRegulationIndex_BRI")
correlation_analysis(ZOO_Corr_DIFF_Neut_CWS, ZOO_Corr_DIFF_Neut_CWNS, "MeanAmp_N2P2_DIFF", "MetacognitionIndex_MI")
correlation_analysis(ZOO_Corr_DIFF_Neut_CWS, ZOO_Corr_DIFF_Neut_CWNS, "MeanAmp_N2P2_DIFF", "GlobalExecutiveComposite_GEC")

correlation_analysis(ZOO_Corr_Go_Neut_CWS, ZOO_Corr_Go_Neut_CWNS, "MeanAmp_N2P2", "sensitivity")
correlation_analysis(ZOO_Corr_Go_Neut_CWS, ZOO_Corr_Go_Neut_CWNS, "MeanAmp_N2P2", "premature_responses")
correlation_analysis(ZOO_Corr_Go_Neut_CWS, ZOO_Corr_Go_Neut_CWNS, "MeanAmp_N2P2", "RT_proper")
correlation_analysis(ZOO_Corr_Go_Neut_CWS, ZOO_Corr_Go_Neut_CWNS, "MeanAmp_N2P2", "inhibit")
correlation_analysis(ZOO_Corr_Go_Neut_CWS, ZOO_Corr_Go_Neut_CWNS, "MeanAmp_N2P2", "shift")
correlation_analysis(ZOO_Corr_Go_Neut_CWS, ZOO_Corr_Go_Neut_CWNS, "MeanAmp_N2P2", "emotionalCntrl")
correlation_analysis(ZOO_Corr_Go_Neut_CWS, ZOO_Corr_Go_Neut_CWNS, "MeanAmp_N2P2", "workingMemory")
correlation_analysis(ZOO_Corr_Go_Neut_CWS, ZOO_Corr_Go_Neut_CWNS, "MeanAmp_N2P2", "BehavioralRegulationIndex_BRI")
correlation_analysis(ZOO_Corr_Go_Neut_CWS, ZOO_Corr_Go_Neut_CWNS, "MeanAmp_N2P2", "MetacognitionIndex_MI")
correlation_analysis(ZOO_Corr_Go_Neut_CWS, ZOO_Corr_Go_Neut_CWNS, "MeanAmp_N2P2", "GlobalExecutiveComposite_GEC")

```
# REGRESSION WITH KNOTS

```{r}
# install.packages("segmented")
library(segmented)
# Assuming df1 is your data frame, and var1 and var2 are the variables of interest
# Fit a segmented linear model with two knots
model <- lm(GlobalExecutiveComposite_GEC ~ MeanAmp_N2P2_DIFF, data = ZOO_Corr_DIFF_Neg_CWS)

# Specify the breakpoints (knots)
breakpoints <- segmented(model, seg.Z = ~MeanAmp_N2P2_DIFF, psi = list(MeanAmp_N2P2_DIFF = c(-4, 2)))

# Print the summary of the segmented model
summary(breakpoints)

# correlation_CWS <- cor.test(predict(breakpoints), ZOO_Corr_DIFF_Neg_CWS$GlobalExecutiveComposite_GEC, use = "complete.obs")

# Create a data frame for prediction
pred_data <- data.frame(MeanAmp_N2P2_DIFF = seq(min(ZOO_Corr_DIFF_Neg_CWS$MeanAmp_N2P2_DIFF), max(ZOO_Corr_DIFF_Neg_CWS$MeanAmp_N2P2_DIFF), length.out = 100))

# Predict the values using the segmented model
pred_values <- predict(breakpoints, newdata = pred_data)

# lwr <- pred_values[, "lwr"]
# upr <- pred_values[, "upr"]

# Create a scatter plot with regression line and confidence interval
ggplot(ZOO_Corr_DIFF_Neg_CWS, aes(x = MeanAmp_N2P2_DIFF, y = GlobalExecutiveComposite_GEC)) +
  geom_point() +
  geom_line(data = pred_data, aes(x = MeanAmp_N2P2_DIFF, y = pred_values), color = "blue") +
  # geom_ribbon(data = pred_data, aes(x = MeanAmp_N2P2_DIFF, ymin = lwr, ymax = upr), 
   #           fill = "blue", alpha = 0.3, linetype = "dashed") +
  labs(title = "Scatter Plot with Regression Line and Confidence Interval",
       x = "Variable 1",
       y = "Variable 2") +
  theme_minimal()

```



