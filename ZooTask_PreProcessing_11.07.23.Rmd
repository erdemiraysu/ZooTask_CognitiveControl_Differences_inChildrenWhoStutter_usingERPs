## R Markdown

---
title: "ZooTask_PreProcessing_11.07.23"
output: html_document
---

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document

```{r setup, include=FALSE}
# Knitting a document simply means taking all the text and code and creating a nicely formatted document in either HTML, PDF, or Word 
knitr::opts_chunk$set(echo = TRUE)
```

# INSTALL NECESSARY PACKAGES:
```{r}
# install.packages("erp.easy")
library(erp.easy)
library(dplyr)
library(Hmisc)
library(ggplot2, quietly = TRUE, warn.conflicts = FALSE)
library(stringr)
library(tidyr)
library(reshape2)
```

# LOCATE FOLDERS:

```{r}
# Locate the folder for the EEG output files (.txt) for old and new nets, replace the file location below with the one in your local device:
path_newnets <- "/Users/aysuerdemir/Desktop/R workspace/ERP_Zoo/CrossSectional/Mix/newnets/"
path_oldnets <- "/Users/aysuerdemir/Desktop/R workspace/ERP_Zoo/CrossSectional/Mix/oldnets/"
# Enter the number of participants in each group:
subs_new <- 70
subs_old <- 12
```

# LOAD DATA:
* Load the data from all subjects into a dataframe for each of the 4 conditions.
* Convert all variables into factors so that the grand average function can work properly.
* Do this separately for old nets and new nets since we will process them differently based on electrode locations (electrode numbers are different)
* Make sure all files are 250m/s sampling rate - downsample beforehand if needed. Code would not run if a child has higher sampling rate. 

```{r}

# Load data into dataframes for each condition separately (the exported .txt files appear separately for each condition):
neg_go <- load.data(path_newnets,"NegGo", subs_new, -100, 999) 
neg_nogo <- load.data(path_newnets,"NegNoGo", subs_new, -100, 999)
neut_go <- load.data(path_newnets,"NeutGo", subs_new, -100, 999)
neut_nogo <- load.data(path_newnets,"NeutNoGo", subs_new, -100, 999)

# Combine all conditions together into a single dataframe:
combo_new <- rbind.data.frame(neg_go, neg_nogo, neut_go, neut_nogo) 
combo_new <- as.data.frame(unclass(combo_new), stringsAsFactors=TRUE)

# Repeat for old nets:
neg_go_old <- load.data(path_oldnets,"NegGo", subs_old, -100, 999) 
neg_nogo_old <- load.data(path_oldnets,"NegNoGo", subs_old, -100, 999)
neut_go_old <- load.data(path_oldnets,"NeutGo", subs_old, -100, 999)
neut_nogo_old <- load.data(path_oldnets,"NeutNoGo", subs_old, -100, 999)

combo_old <- rbind.data.frame(neg_go_old, neg_nogo_old, neut_go_old, neut_nogo_old) 
combo_old <- as.data.frame(unclass(combo_old),stringsAsFactors=TRUE)

head(combo_old)

```

# SPECIFY THE ELECTRODE NUMBERS FOR P2, N2 and P3:

FCz = frontrocentral - midline
FC4 = frontrocentral - right
FC3 = frontrocentral - left

Pz = parietal - midline
P4 = parietal - right
P3 = parietal - left

```{r}

# new nets: 

FCz_newnets <- c("V18", "V16", "V10", "V19", "V11", "V4", "V12", "V5", "V6")
FC4_newnets <- c("V3","V123","V124", "V117", "V118") 
FC3_newnets <- c("V23","V27","V24",  "V28", "V20")

Pz_newnets <- c("V54","V79","V61", "V62","V78", "V67", "V72", "V77")
P4_newnets <- c("V85", "V86", "V91" , "V92" ,"V97", "V98")
P3_newnets <- c("V51", "V52","V53", "V59", "V60", "V47")

# repeat for old nets

FCz_oldnets <- c("V19","V16", "V10", "V20","V11", "V4","V12","V5","V6")
FC4_oldnets <- c("V3","V123","V119", "V123","V118")
FC3_oldnets <- c("V24","V25","V21", "V28","V29")

Pz_oldnets <- c( "V54","V62","V80", "V61","V68","V79", "V67", "V73","V78")
P4_oldnets <- c("V87","V99", "V86", "V93", "V98", "V92")
P3_oldnets <- c("V53","V48", "V52", "V60", "V51", "V59") 

```

# CHECK OUT INDIVIDUAL WAVEFORMS:
# USING MOSAIC YOU CAN CREATE AN AVERAGE WAVEFORM FOR EACH PARTICIPANT IN EACH GROUP & NET LOCATION:

```{r}
#Create average waveform plots for each subject in a single, multiplot window
mosaic(combo_new, FCz_newnets, cols = 3, rows = 2)
mosaic(combo_new, Pz_newnets, cols = 3, rows = 2)

mosaic(combo_old, FCz_oldnets, cols = 3, rows = 2)
mosaic(combo_old, Pz_oldnets, cols = 3, rows = 2)

```


# CHECK OUT GRADN AVERAGES USING GRANDAVERAGE() FUNCTION

```{r}
# grand average plots the grand average waveform for each condition present in the dataframe you provide.
# A color-coded and labeled legend is generated with the plot for ease of identification of each condition.
grandaverage(combo_new, FCz_newnets)
grandaverage(combo_new, Pz_newnets)
# butterfly plots all individual waveforms for the condition specified by the stim argument(i.e.,a butterfly plot).
# The grandaverage waveform is also plotted,using a red line.
butterfly(combo_new,FCz_newnets, stim=1)
```

# CODE BELOW GETS ALL THE MEASURES (N2, P2, P3) FROM OLD AND NEW NET DATA, COMBINE THEM TOGETHER AND IT SAVES THE DATA INTO A FINAL COMBO SPREADSHEET:
# CHECK THE WINDOW RANGE FOR EACH ERP COMPONENT AND ADJUST AS NEEDED!

* The dependent measures we use are mean amplitude (microvolts) and latency (in ms) for statistical analysis. 
* m.measures gives the mean amplitude for a specific window and its dt dev. along with its graph. 
specify lgnd = "n" (no legend) if you do not want the legend 
* p.measures calculates local or simple peak amplitude and latency for each condition in the data frame. Use latency only from p.measures
* pol = The polarity of peaks to favor when multiple peaks are present. Entering "pos" will locate the most positive peak. Entering "neg" will locate the most negative peak. Entering "abs" will find the greatest deviation from 0, regardless of the polarity.  

# P2 between 180â€“280 ms after stimulus onset at frontal, frontocentral and central electrode sites.
# N2 between 320,520 ms after stimulus onset at frontal, frontocentral and central electrode sites.
# P3 between 450-750 ms after stimulus onset at parietal electrode sites.
```{r}

# Get the mean Amplitude measures from the NEW net:
MeanAmp_P2_FCz_newnets <- (m.measures(combo_new, FCz_newnets, window=c(180,280)))
MeanAmp_P2_FC4_newnets <- (m.measures(combo_new, FC4_newnets, window=c(180,280)))
MeanAmp_P2_FC3_newnets <- (m.measures(combo_new, FC3_newnets, window=c(180,280))) 

MeanAmp_N2_FCz_newnets <- (m.measures(combo_new, FCz_newnets, window=c(320,520)))  
MeanAmp_N2_FC4_newnets <- (m.measures(combo_new, FC4_newnets, window=c(320,520)))
MeanAmp_N2_FC3_newnets<- (m.measures(combo_new, FC3_newnets, window=c(320,520)))  

MeanAmp_P3_Pz_newnets <- (m.measures(combo_new, Pz_newnets, window=c(450,750)))  
MeanAmp_P3_P4_newnets <- (m.measures(combo_new, P4_newnets, window=c(450,750)))  
MeanAmp_P3_P3_newnets <- (m.measures(combo_new, P3_newnets, window=c(450,750)))  

# We need to combine these but each one of these datasets use the same variable name - Mean Amplitude. 
# Below is a function that will allow us to rename the variables in multiple datasets in a similar way:

rename_datasets_amplitude <- function(dataset_list, new_col_names){
for (i in 1:length(dataset_list)){
assign(dataset_list[i], rename(get(dataset_list[i]),
!!new_col_names[i] := "Mean Amplitude"), envir = .GlobalEnv)
}
}

datasets <- c("MeanAmp_P2_FCz_newnets", "MeanAmp_P2_FC4_newnets", "MeanAmp_P2_FC3_newnets",
              "MeanAmp_N2_FCz_newnets", "MeanAmp_N2_FC4_newnets", "MeanAmp_N2_FC3_newnets",
              "MeanAmp_P3_Pz_newnets", "MeanAmp_P3_P4_newnets", "MeanAmp_P3_P3_newnets")

new_column_names <- c("MeanAmp_P2_FCz", "MeanAmp_P2_FC4", "MeanAmp_P2_FC3",
                      "MeanAmp_N2_FCz", "MeanAmp_N2_FC4", "MeanAmp_N2_FC3",
                      "MeanAmp_P3_Pz", "MeanAmp_P3_P4", "MeanAmp_P3_P3")

rename_datasets_amplitude(datasets, new_column_names)

#  load multiple datasets into the workspace     
datasets_list <- mget(datasets)

# Using the `Reduce()` function to merge multiple data frames stored in `datasets_list` into a single data frame called `df_merge1`. 
# It does this by merging each data frame in the list with the others, based on the columns "Subject" and "Trial Type".


merge_datasets_amplitude <- function(datasets_list) {
Reduce(function(x, y) {
x <- x[, !(names(x) %in% "Standard Dev")] # ignore Standard Dev column from the first dataframe, do not merge it
y <- y[, !(names(y) %in% "Standard Dev")] # ignore Standard Dev column from the next dataframe, do not merge it
merge(x, y, by=c("Subject", "Trial Type"))
}, datasets_list)
}

# Run the function
df_merge1 <- merge_datasets_amplitude(datasets_list) # use the function to merge the new data frames

# Get the Latency measures from the NEW net:
Latency_P2_FCz_newnets <- (p.measures(combo_new, FCz_newnets, window=c(180,280), pol="pos"))
Latency_P2_FC4_newnets <- (p.measures(combo_new, FC4_newnets, window=c(180,280), pol="pos"))
Latency_P2_FC3_newnets <- (p.measures(combo_new, FC3_newnets, window=c(180,280), pol="pos"))

Latency_N2_FCz_newnets <- (p.measures(combo_new, FCz_newnets, window=c(320,520), pol="neg"))  
Latency_N2_FC4_newnets <- (p.measures(combo_new, FC4_newnets, window=c(320,520), pol="neg"))  
Latency_N2_FC3_newnets <- (p.measures(combo_new, FC3_newnets, window=c(320,520), pol="neg")) 

Latency_P3_Pz_newnets <- (p.measures(combo_new, Pz_newnets, window=c(450,750), pol="pos"))
Latency_P3_P4_newnets <- (p.measures(combo_new, P4_newnets, window=c(450,750), pol="pos"))
Latency_P3_P3_newnets <- (p.measures(combo_new, P3_newnets, window=c(450,750), pol="pos"))


# Function `rename_datasets()` that renames the columns "Peak Latency" and "Peak Amplitude" in each data frame from a list of data frames (`dataset_list`)

rename_datasets_latency <- function(dataset_list, new_col_name1, new_col_name2){
for (i in 1:length(dataset_list)){
temp_data <- get(dataset_list[i])
names(temp_data)[names(temp_data) == "Peak Latency"] <- new_col_name1[i]
names(temp_data)[names(temp_data) == "Peak Amplitude"] <- new_col_name2[i]
assign(dataset_list[i], temp_data, envir = .GlobalEnv)
}
}

datasets <- c("Latency_P2_FCz_newnets", "Latency_P2_FC4_newnets", "Latency_P2_FC3_newnets",
              "Latency_N2_FCz_newnets", "Latency_N2_FC4_newnets", "Latency_N2_FC3_newnets",
              "Latency_P3_Pz_newnets", "Latency_P3_P4_newnets", "Latency_P3_P3_newnets")

new_column_names1 <- c("Latency_P2_FCz", "Latency_P2_FC4", "Latency_P2_FC3",
                      "Latency_N2_FCz", "Latency_N2_FC4", "Latency_N2_FC3",
                      "Latency_P3_Pz", "Latency_P3_P4", "Latency_P3_P3")

new_column_names2 <- c("PeakAmp_P2_FCz", "PeakAmp_P2_FC4", "PeakAmp_P2_FC3",
                      "PeakAmp_N2_FCz", "PeakAmp_N2_FC4", "PeakAmp_N2_FC3",
                      "PeakAmp_P3_Pz", "PeakAmp_P3_P4", "PeakAmp_P3_P3")

rename_datasets_latency(datasets, new_column_names1, new_column_names2)

datasets_list <- mget(datasets)


merge_datasets_latency <- function(datasets_list) {
Reduce(function(x, y) {
merge(x, y, by=c("Subject", "Trial Type"))
}, datasets_list)
}

# Run the function
df_merge2 <- merge_datasets_latency(datasets_list) # use the function to merge the new data frames

# Combine the 2 dataframes
ERP_newnets <- full_join(df_merge1, df_merge2)

head(ERP_newnets)
# remove standard dev column:
# ERP_newnets <- ERP_newnets %>% select(-`Standard Dev`)
```


# REPEAT FOR OLD NETS!
```{r}

MeanAmp_P2_FCz_oldnets <- (m.measures(combo_old, FCz_oldnets, window=c(180,280)))
MeanAmp_P2_FC4_oldnets <- (m.measures(combo_old, FC4_oldnets, window=c(180,280)))
MeanAmp_P2_FC3_oldnets <- (m.measures(combo_old, FC3_oldnets, window=c(180,280)))

MeanAmp_N2_FCz_oldnets <- (m.measures(combo_old, FCz_oldnets, window=c(320,520)))  
MeanAmp_N2_FC4_oldnets <- (m.measures(combo_old, FC4_oldnets, window=c(320,520)))  
MeanAmp_N2_FC3_oldnets <- (m.measures(combo_old, FC3_oldnets, window=c(320,520)))  

MeanAmp_P3_Pz_oldnets <- (m.measures(combo_old, Pz_oldnets, window=c(450,750)))  
MeanAmp_P3_P4_oldnets <- (m.measures(combo_old, P4_oldnets, window=c(450,750)))  
MeanAmp_P3_P3_oldnets <- (m.measures(combo_old, P3_oldnets, window=c(450,750)))  


datasets <- c("MeanAmp_P2_FCz_oldnets", "MeanAmp_P2_FC4_oldnets", "MeanAmp_P2_FC3_oldnets",
              "MeanAmp_N2_FCz_oldnets", "MeanAmp_N2_FC4_oldnets", "MeanAmp_N2_FC3_oldnets",
              "MeanAmp_P3_Pz_oldnets", "MeanAmp_P3_P4_oldnets", "MeanAmp_P3_P3_oldnets")

new_column_names <- c("MeanAmp_P2_FCz", "MeanAmp_P2_FC4", "MeanAmp_P2_FC3",
                      "MeanAmp_N2_FCz", "MeanAmp_N2_FC4", "MeanAmp_N2_FC3",
                      "MeanAmp_P3_Pz", "MeanAmp_P3_P4", "MeanAmp_P3_P3")

rename_datasets_amplitude(datasets, new_column_names)
                
datasets_list <- mget(datasets)

df_merge1_old <- merge_datasets_amplitude(datasets_list) # use the function to merge the new data frames



Latency_P2_FCz_oldnets <- (p.measures(combo_old, FCz_oldnets, window=c(180,280), pol="pos"))
Latency_P2_FC4_oldnets <- (p.measures(combo_old, FC4_oldnets, window=c(180,280), pol="pos"))
Latency_P2_FC3_oldnets <- (p.measures(combo_old, FC3_oldnets, window=c(180,280), pol="pos"))

Latency_N2_FCz_oldnets <- (p.measures(combo_old, FCz_oldnets, window=c(320,520), pol="neg"))  
Latency_N2_FC4_oldnets <- (p.measures(combo_old, FC4_oldnets, window=c(320,520), pol="neg"))  
Latency_N2_FC3_oldnets <- (p.measures(combo_old, FC3_oldnets, window=c(320,520), pol="neg")) 

Latency_P3_Pz_oldnets <- (p.measures(combo_old, Pz_oldnets, window=c(450,750), pol="pos"))
Latency_P3_P4_oldnets <- (p.measures(combo_old, P4_oldnets, window=c(450,750), pol="pos"))
Latency_P3_P3_oldnets <- (p.measures(combo_old, P3_oldnets, window=c(450,750), pol="pos"))


datasets <- c("Latency_P2_FCz_oldnets", "Latency_P2_FC4_oldnets", "Latency_P2_FC3_oldnets",
              "Latency_N2_FCz_oldnets", "Latency_N2_FC4_oldnets", "Latency_N2_FC3_oldnets",
              "Latency_P3_Pz_oldnets", "Latency_P3_P4_oldnets", "Latency_P3_P3_oldnets")

new_column_names1 <- c("Latency_P2_FCz", "Latency_P2_FC4", "Latency_P2_FC3",
                      "Latency_N2_FCz", "Latency_N2_FC4", "Latency_N2_FC3",
                      "Latency_P3_Pz", "Latency_P3_P4", "Latency_P3_P3")

new_column_names2 <- c("PeakAmp_P2_FCz", "PeakAmp_P2_FC4", "PeakAmp_P2_FC3",
                      "PeakAmp_N2_FCz", "PeakAmp_N2_FC4", "PeakAmp_N2_FC3",
                      "PeakAmp_P3_Pz", "PeakAmp_P3_P4", "PeakAmp_P3_P3")

rename_datasets_latency(datasets, new_column_names1, new_column_names2)

datasets_list <- mget(datasets)

df_merge2_old <- merge_datasets_latency(datasets_list) # use the function to merge the new data frames

                
# Combine the 2 dataframes
ERP_oldnets <- full_join(df_merge1_old, df_merge2_old)

# Combine old +new
ERP <- full_join(ERP_oldnets, ERP_newnets)

# Remove Grand Ave from data, order by subject name and reset the index:
ERP <- ERP[!(ERP$Subject=="Grand Avg"),]
ERP <- with(ERP,  ERP[order(Subject) , ])
rownames(ERP) <- NULL # Reset index

```
# MORE RE-FORMATTING:

```{r}

# CREATE A NEW COLUMN by taking the difference between N2-P2
ERP$MeanAmp_N2P2_FCz <- ERP$MeanAmp_N2_FCz - ERP$MeanAmp_P2_FCz
ERP$PeakAmp_N2P2_FCz <- ERP$PeakAmp_N2_FCz - ERP$PeakAmp_P2_FCz

ERP$MeanAmp_N2P2_FC4 <- ERP$MeanAmp_N2_FC4 - ERP$MeanAmp_P2_FC4
ERP$PeakAmp_N2P2_FC4 <- ERP$PeakAmp_N2_FC4 - ERP$PeakAmp_P2_FC4

ERP$MeanAmp_N2P2_FC3 <- ERP$MeanAmp_N2_FC3 - ERP$MeanAmp_P2_FC3
ERP$PeakAmp_N2P2_FC3 <- ERP$PeakAmp_N2_FC3 - ERP$PeakAmp_P2_FC3

# REORGANIZE STIMTAG VARIABLE AS TWO SEPERATE VARIABLES: EMOTION AND CONDITION - EACH WITH TWO LEVELS 
ERP <- ERP %>%
mutate(Emotion = str_extract(`Trial Type`, "Neut|Neg"),
       Condition = str_extract(`Trial Type`, "Go|NoGo"))

# RESHAPE TO LONG FORMAT

ERP_long <- pivot_longer(ERP, 
  cols = -c(Subject, `Trial Type`, `Condition`, `Emotion`), 
  names_to = c(".value",  "Electrode"),
  names_pattern = "^(MeanAmp_P2|MeanAmp_N2|MeanAmp_N2P2|MeanAmp_P3|PeakAmp_P2|PeakAmp_N2|PeakAmp_N2P2|PeakAmp_P3|Latency_P2|Latency_N2|Latency_P3)_(.+)$",
  values_to = "Value"
) %>%
  mutate(
    Region = ifelse(grepl("^FC", Electrode), "Frontocentral",  "Parietal"),
    Laterality = ifelse(grepl("4", Electrode), "Right", 
               ifelse(grepl("3", Electrode), "Left", "Midline"))
  ) %>%
  select(-Electrode)


ERP_long <- pivot_longer(ERP, 
  cols = -c(Subject, `Trial Type`, `Condition`, `Emotion`), 
  names_to = c(".value",  "Electrode"),
  names_pattern = "^(MeanAmp_P2|MeanAmp_N2|MeanAmp_N2P2|MeanAmp_P3|PeakAmp_P2|PeakAmp_N2|PeakAmp_N2P2|PeakAmp_P3|Latency_P2|Latency_N2|Latency_P3)_(.+)$",
  values_to = "Value"
) %>%
  mutate(
    Laterality = ifelse(grepl("4", Electrode), "Right", 
               ifelse(grepl("3", Electrode), "Left", "Midline"))
  ) %>%
  select(-Electrode)


ERP_long <- ERP_long %>%
  group_by(Subject, `Trial Type`, Emotion, Condition, Laterality) %>%
  summarise(across(everything(), ~mean(., na.rm = TRUE)), .groups = 'drop')


# Write to a csv file:
write.csv(ERP_long, "/Users/aysuerdemir/Desktop/R workspace/ERP_Zoo/CrossSectional/Mix/ERP_long")
head(ERP_long)
```


# LOAD AND MERGE WITH INTAKE INFO:
* Load data exported from RedCap, named: Intake_Stuttering_Language_Varbls_for_Zoo_and_Reactivity
* Feature engineer necessary variables and merge the above ERP dataset with TalkerGroup, Gender, Age info along with Stuttering and Language Scores

```{r}

# Load DataSet: 
intake <- read.csv(file = '/Users/aysuerdemir/Desktop/R workspace/ERP_Zoo/CognitiveEmotionalLi-IntakeDiagnosticData_DATA_2023-10-25_0818.csv')

# Subject IDs include the visit number in the combo dataset if it is NOT the first time point. 
# Do the same here: Combine visit number with subject and create a new Subject variable so that it matches the combo:
intake <- intake  %>%
  mutate(Subject = ifelse(redcap_event_name !="t1_arm_1", paste0(part_id_status, "T", visitnumber), part_id_status)) 

# Create a new variable representing final sldper100words ("disfluency_sldper100words_final) by taking disfluency_sldper100words from CVD as primary, 
# but in the case that this data is missing, take the disfluency scores from CVE:
intake <- intake  %>%
  mutate(disfluency_sldper100words_final = ifelse(!is.na(disfluency_sldper100words), disfluency_sldper100words, disfluency_sldper100words_cve)) 

# Create a final talker group variable ("talkergroup_final) using disfluency_sldper100words_final and talker group based on parent report:
# 1: CWS, 0:CWNS, 9:unidentified
intake <- intake  %>%
  mutate(talkergroup_final = ifelse((disfluency_sldper100words_final >= 3 | calculator_talkergroup_parent == 1), 1,
                                          ifelse((disfluency_sldper100words_final < 3 & calculator_talkergroup_parent == 0), 0, 9)))  
                    
# Take the relevant columns from intake dataset
# You may update this to take more columns into the dataset:
intake <-  subset(intake, select=c('Subject','calculator_age_cve','calculator_gender_cve','race', 'ethnicity',
                                   'calculator_talkergroup_parent','tso_calculated',
                                   'disfluency_sldper100words','ssi_total', 
                                   'disfluency_sldper100words_final', 'talkergroup_final',
                                   "gfta_standard", "ppvt_standard", "evt_standard",             
                                   'teld_rec_standard','teld_exp_standard', "teld_spokenlang_standard",
                                   'tocs_1_total', 'tocs_2_total', 'tcs_total',
                                   'eprime_condorder_zootask','cve_comments','comments_tasks','handedness_zoo'))

# Merge with the main dataset using SUBJECT
FULL <- merge(ERP_long, intake, by=c("Subject"), all.x = TRUE)
head(FULL)  

# Print the unique subject codes
unique_codes<- unique(FULL$Subject)
unique_codes <- as.data.frame(unique_codes)
unique_codes

# Making sure the Final FULL dataset has the all subjects coded (initially specified by SUBS - subject number):
subs = 82
(nrow(FULL)/12) == subs # This should give TRUE! 12 rows per subject
```

# Show the rows where talkergroup_final = 9 or NA :
undefined_talkergroup <- subset(FULL, talkergroup_final == 9 |  is.na(talkergroup_final))
print(unique(undefined_talkergroup$Subject))

# FIND THE UNDEFINED (9) TALKER GROUPS AND MANUALLY MARK THEM AS EITHER 1 or 0 if needed:
# Replace NA values in a specific column based on a condition:
FULL$talkergroup_final <- ifelse(FULL$Subject == "JA092118", 0, FULL$talkergroup_final)
FULL$talkergroup_final <- ifelse(FULL$Subject == "LG100721T2", 1, FULL$talkergroup_final)
FULL$talkergroup_final <- ifelse(FULL$Subject == "LW102219T3", 1, FULL$talkergroup_final)

# Making sure no 9 or NA remained:
any(FULL$talkergroup_final == 9 | is.na(FULL$talkergroup_final))


```{r}
# How many kids in each group?
talkergroup_counts <- table(FULL$talkergroup_final)
print(talkergroup_counts)/12
```
# ALSO ADD THE AVAILABLE LONGITUDINAL CATEGORIES:

# Load DataSet: 
longitudinal_groups <- read.csv(file = '/Users/aysuerdemir/Desktop/R workspace/ERP_Zoo/LongitudinalClassifications_9.10.23.csv')

# Merge with the main dataset using SUBJECT
FULL <- merge(FULL, longitudinal_groups[, c("Subject", "Longitudinal_Group_0Rec_1Per_2Und")], by=c("Subject"), all.x = TRUE)

# Making sure the Final FULL dataset has the all subjects coded (initially specified by SUBS - subject number):
(nrow(FULL)/4) == subs # This should give TRUE!

# How many kids in each group?
longtgroup_counts <- table(FULL$Longitudinal_Group_0Rec_1Per_2Und)
print(longtgroup_counts)/4

```{r}



```

# LOAD AND MERGE WITH BEHAVIORAL DATA:
* for GO and NOGO conditions use ShowStim.RESP to compute the accuracy. 
* ShowStim.RESP: 4 it means the child pushed the button (accurate for Go), NA means no response (accurate for NoGo). 

Trials with responses faster than 200 ms were eliminated from the analysis, as they were too quick to reflect responding to the current stimulus.

Go proportion correct 0.75 0.185 0.07â€“1.0 )1.03 0.76
Go RT (ms) 934 155.5 378â€“1,300 0.03 )0.29
No-go proportion correct 0.74 0.312 0â€“1 )1.16 0.02
Sensitivity (dÂ¢) 1.54 1.114 )1.27â€“3.77 )0.44 )0.45

Mean reaction times in ms for CWS and CWNS.
Group Hits False alarms
M SD M SD
CWS 509 132 382* 111
CWNS 534 104 457* 145

For each participant, the frequency of the following variables was automatically recorded and stored: 
(a) â€˜hitsâ€™ (when a Go-stimulus was followed by a response falling between 200 and 2300 ms after stimulus onset), 
(b) â€˜missesâ€™ (when a Gostimulus was not followed by a response), 
(c) â€˜false alarmsâ€™ (when a NoGo-stimulus was followed by pressing the response button between 200 and 2300 ms after stimulus onset), and 
(d) â€˜premature responsesâ€™ (when the response button was pressed between 0 and 200 ms after stimulus onset). 
In addition, for the variables â€˜hitsâ€™ and â€˜false alarmsâ€™ mean RTs were also recorded.

In case a child exhibited a false alarm or premature response on two or more trials out of the 48 trials, this was defined as exhibiting â€˜multiple false alarmsâ€™ or â€˜multiple premature responsesâ€™. In addition, for the variables â€˜hitsâ€™ and â€˜false alarmsâ€™ mean RTs were also recorded.

```{r}
# Load the file:
accuracy <- read.csv(file = '/Users/aysuerdemir/Desktop/R workspace/ERP_Zoo/Merged_Zoo_10.03.23.csv')
# Take only the relevant variables:
accuracy <-  subset(accuracy, select=c('Name','VisitNumber','ShowStim.ACC','ShowStim.RESP','ShowStim.RT','StimTag'))

# Convert all empty strings to NA
accuracy <- replace(accuracy, accuracy == "", NA)
# accuracy$ShowStim.RESP <- na_if(accuracy$ShowStim.RESP, "")

# Combine visit number with subject and create a new Subject variable for eprime so that it matches the FULL
accuracy <- accuracy  %>% 
  mutate(Subject = ifelse(VisitNumber != 1, paste0(Name, "T", VisitNumber), Name)) 

# Print unique subjects in FULL
unique_subjects <- unique(FULL$Subject)

# Filter 'accuracy' dataframe
accuracy <- accuracy[accuracy$`Subject` %in% unique_subjects, ]

# Unique counts for ShowStim.RESP
unique_codes <- unique(accuracy$ShowStim.RESP)
counts <- as.data.frame(table(accuracy$ShowStim.RESP))
counts



# Check out the class types for each variable. 
sapply(accuracy, class)
# For ShowStim.RESP response 4 is a "character", not integer. 
print(class(accuracy$ShowStim.RESP))

# Convert character 4 for ShowStim.RESP to integer
# accuracy$ShowStim.RESP <- as.integer(accuracy$ShowStim.RESP)


# For each participant, the frequency of the following variables was automatically recorded and stored: 
# (a) â€˜hitsâ€™ (when a Go-stimulus was followed by a response falling between 200 and 2300 ms after stimulus onset), 
# (b) â€˜missesâ€™ (when a Go stimulus was not followed by a response), 
# (c) â€˜false alarmsâ€™ (when a NoGo-stimulus was followed by pressing the response button between 200 and 2300 ms after stimulus onset), and 
# (d) â€˜premature responsesâ€™ (when the response button was pressed between 0 and 200 ms after stimulus onset). 

# Remove the special character trials, and only keep those trials with proper number resonses.
unique(accuracy$ShowStim.RESP)
accuracy <- accuracy[is.na(accuracy$ShowStim.RESP) | accuracy$ShowStim.RESP %in% c(1,2,3,4,5,6) , ]

# Drop the 2 rows with NA:
accuracy <- accuracy[!is.na(accuracy$StimTag), ]

# CREATE THE NEW VARIABLES:
# Our max RT is 2023

accuracy <- accuracy %>%
  mutate(behavior = case_when(
    (ShowStim.RT >= 200 & ShowStim.RESP == 4) & (StimTag %in% c("negG", "neuG")) ~ "correct_go",
    (ShowStim.RT == 0) & (StimTag %in% c("negG", "neuG")) ~ "wrong_go",
    (ShowStim.RT < 200 & ShowStim.RT > 0 & ShowStim.RESP %in% 1:6) & (StimTag %in% c("negG", "neuG")) ~ "premature_go",
    (ShowStim.RT == 0 & (StimTag %in% c("negN", "neuN"))) ~ "correct_nogo",
    (ShowStim.RT > 200 & ShowStim.RESP %in% 1:6) & (StimTag %in% c("negN", "neuN")) ~ "wrong_nogo_falsealarm",
    (ShowStim.RT < 200 & ShowStim.RT > 0 & ShowStim.RESP %in% 1:6) & (StimTag %in% c("negN", "neuN")) ~ "premature_nogo",
    TRUE ~ NA_character_   # is a catch-all condition that assigns `NA` to any rows that don't meet any of the previous conditions
  ))

# Calculate the proportions
accuracy_proportions <- accuracy %>%
  
  group_by(Subject, StimTag) %>%
  summarise(
  correct_go = sum(behavior == "correct_go", na.rm = TRUE),
  wrong_go = sum(behavior == "wrong_go", na.rm = TRUE),
  premature_go = sum(behavior == "premature_go", na.rm = TRUE),
  accuracy_go_proportion = (correct_go / (correct_go + wrong_go +premature_go)) *100 ,
  
  correct_nogo = sum(behavior == "correct_nogo", na.rm = TRUE),
  wrong_nogo_falsealarm = sum(behavior == "wrong_nogo_falsealarm", na.rm = TRUE),
  premature_nogo = sum(behavior == "premature_nogo", na.rm = TRUE),
  accuracy_nogo_proportion = (correct_nogo / (correct_nogo + wrong_nogo_falsealarm +premature_nogo))*100,
  
  premature_go = sum(behavior == "premature_go", na.rm = TRUE),
  premature_go_proportion = (premature_go / (correct_go + premature_go))*100,
  
  premature_nogo = sum(behavior == "premature_nogo", na.rm = TRUE),
  premature_nogo_proportion = (premature_nogo / (wrong_nogo_falsealarm + premature_nogo))*100,
  
RT_proper_go = mean(ifelse(ShowStim.RT >= 200 & (StimTag == 'neuG' | StimTag == 'negG'), ShowStim.RT, NA), na.rm = TRUE),
RT_all_go = mean(ifelse((StimTag == 'neuG' | StimTag == 'negG') & ShowStim.RT != 0, ShowStim.RT, NA), na.rm = TRUE),
RT_nogo_falsealarm = mean(ifelse((behavior == 'wrong_nogo_falsealarm'), ShowStim.RT, NA), na.rm = TRUE)
)

# Combine accuracy go and accuracy nogo together,  premature go and nogo together, and RT go and RT nogo together:
# Since 'accuracy_go' and 'accuracy_nogo' do not overlap (one of them is always NA for a given row), you can use the `coalesce` function to pick the non-NA value

accuracy_proportions_final <- accuracy_proportions %>%
  mutate(
    accuracy = coalesce(accuracy_go_proportion, accuracy_nogo_proportion),
    premature_responses = coalesce(premature_go_proportion, premature_nogo_proportion),
    RT_proper = coalesce(RT_proper_go, RT_nogo_falsealarm))

# Subset to main variables only
accuracy_proportions_final <-  subset(accuracy_proportions_final, select=c('Subject', "StimTag", "accuracy", "premature_responses", "RT_proper", "RT_all_go"))

# Rename the labels for StimTags on eprime data
eprime <- accuracy_proportions_final %>% 
  mutate(StimTag = recode(StimTag, "negG" = "NegGo", "negN" = "NegNoGo", "neuG" = "NeutGo", "neuN" = "NeutNoGo"))

head(eprime)

```

# COMBINE FULL WITH EPRIME

```{r}
# Replace Trial Type in FULL with "StimTag" to be able to merge with eprime data
FULL <- FULL %>%
  dplyr::rename("StimTag" = "Trial Type")

# COMBINE ALL!!
ZOO <- merge(FULL, eprime, by=c("Subject", "StimTag"), all.x = TRUE)
head(ZOO)

```


# See how many kids have missing accuracy data and manually add them:
# ADD THIS KID MANUALLY _ ACCURACY TAKEN FROM NETSTATION:

```{r}
# See how many kids have missing accuracy data and manually add them:

subset_NA_eprime_data <- subset(ZOO, is.na(ZOO$accuracy))
unique(subset_NA_eprime_data$Subject)


# Identify the specific row
rows_to_update_NeutNoGo <- which(ZOO$Subject == "RB101619" & ZOO$StimTag == "NeutNoGo")
rows_to_update_NeutGo <- which(ZOO$Subject == "RB101619" & ZOO$StimTag == "NeutGo")
rows_to_update_NegNoGo <- which(ZOO$Subject == "RB101619" & ZOO$StimTag == "NegNoGo")
rows_to_update_NegGo <- which(ZOO$Subject == "RB101619" & ZOO$StimTag == "NegGo")

# Replace the accuracy value
ZOO$accuracy[rows_to_update_NeutNoGo] <- 50
ZOO$accuracy[rows_to_update_NeutGo] <- 99
ZOO$accuracy[rows_to_update_NegNoGo] <- 42.5
ZOO$accuracy[rows_to_update_NegGo] <- 99

ZOO[ZOO$Subject == "RB101619",]

```


# LOAD and merge with trail numbers DF

```{r}
# Load the file:
trialnum <- read.csv(file = '/Users/aysuerdemir/Desktop/R workspace/ERP_Zoo/Zoo_trialnumber_used_10.03.23.csv')

# convert the dataset to long format:
# id.vars argument specifies which columns in the original data frame should remain as they are without being transformed.
# measure.vars argument specifies which columns in the original data frame should be melted
# The variable.name argument specifies the name of the new column that will store the variable names from the measure.vars
# The value.name argument specifies the name of the new column that will store the values from the measure.vars.
trialnum_long <- melt(trialnum, id.vars = c("Subject"),
                     measure.vars = c("NeutNoGo","NeutGo",
                                      "NegNoGo", "NegGo"), 
                     variable.name = "StimTag", 
                     value.name ="TrialNum")

ZOO <- merge(ZOO, trialnum_long, by=c("Subject", "StimTag"), all.x = TRUE)

```

# WRITE THE FINAL DATAFRAME INTO CSV AND SAVE TO LOCAL DRIVE:
```{r}

# WRITE THE FINAL DATAFRAME INTO CSV AND SAVE TO LOCAL DRIVE:
write.csv(ZOO, "/Users/aysuerdemir/Desktop/R workspace/ERP_Zoo/CrossSectional/Mix/ZOO.csv")
head(ZOO)

```


# REMOVE THESE KIDS BASED ON  LOWER ACCURACY + NEGATIVE EEG COMMENTS:

```{r}
ZOO_bad_subjects <- ZOO %>%
  group_by(Subject) %>%
  filter(all(accuracy[StimTag == "NeutNoGo"] <= 40) |
         all(accuracy[StimTag == "NegNoGo"] <= 40) |
         all(accuracy[StimTag == "NeutGo"] <= 70) |
         all(accuracy[StimTag == "NegGo"] <= 70))

bad_subjects = unique(ZOO_bad_subjects$Subject)
bad_subjects

# READ THE COMMENTS FOR THOSE LOW ACCURACY KIDS:
ZOO_filtered <- dplyr::filter(ZOO, Subject %in% bad_subjects)
ZOO_filtered <-  subset(ZOO_filtered, select=c('Subject','talkergroup_final','StimTag','accuracy', 'TrialNum', 'calculator_age_cve','RT_proper', 'cve_comments','comments_tasks','handedness_zoo'))
ZOO_filtered <- ZOO_filtered %>% distinct() # Use distinct function to remove duplicates
print(ZOO_filtered)

# REMOVE THESE KIDS with <30% accuracy in Nogo, and <60% in Go. 
subjects_to_remove <- c("EG030618","HH061919","WS051018")      

ZOO_good <- ZOO
ZOO_good <- dplyr::filter(ZOO_good, !Subject %in% subjects_to_remove)

write.csv(ZOO_good, "/Users/aysuerdemir/Desktop/R workspace/ERP_Zoo/CrossSectional/Mix/ZOO_good.csv")

```


# DRAW N2P2 and P3 WAVEFORM GRAPHS YOURSELF

```{r}

# Calculate the average of specific columns (as specificed by these electrode numbers below) across all rows and create a new column with these averages
# Combine all conditions together into a single dataframe
# This step is necessary to reverse the unclass() function we have used above. 
# We need to create subsets from the original combo dataset first ADN THEN unclass before using m.measures()
combo_new <- rbind.data.frame(neg_go, neg_nogo, neut_go, neut_nogo) 
combo_old <- rbind.data.frame(neg_go_old, neg_nogo_old, neut_go_old, neut_nogo_old) 

# Add the "talkergroup_final" column from the "FULL" dataset to the "combo" dataset based on the common "Subject" column
combo_with_group_new <- combo_new %>%
  mutate(talkergroup_final = FULL$talkergroup_final[match(Subject, FULL$Subject)])

combo_with_group_old <- combo_old %>%
  mutate(talkergroup_final = FULL$talkergroup_final[match(Subject, FULL$Subject)])

# REMOVE THESE THREE KIDS FROM THE DATASET:
combo_with_group_new <- dplyr::filter(combo_with_group_new, Subject!="EG030618", Subject!="HH061919", Subject!="WS051018")


# CREATE MEAN N2P2 AND P3 VALUES FOR EACH ROW (TIMEPOINT) USING THE SPECIFIED ELECTRODE NUMBERS 

newnet_rawdata <- combo_with_group_new  %>%
    mutate(
    N2P2_waveform = rowMeans(select(., all_of(FCz_newnets))),
    P3_waveform = rowMeans(select(., all_of(Pz_newnets)))
    )

oldnet_rawdata <- combo_with_group_old  %>%
    mutate(
    N2P2_waveform = rowMeans(select(., all_of(FCz_oldnets))),
    P3_waveform = rowMeans(select(., all_of(Pz_oldnets)))
    )

# Combine old and new net data together:
rawdata <- full_join(newnet_rawdata, oldnet_rawdata)


# How many kids in each group?
talkergroup_counts <- table(rawdata$talkergroup_final)
print(talkergroup_counts)/(275*4)


# CREATE A SINGLE SUMMARY WAVEFORM FOR N2P2 AND P3 ACROSS ALL PARTICIPANTS IN EACH GROUP
summary_waveforms <-
  rawdata %>%
  group_by(Stimulus, Time, talkergroup_final) %>%
  summarise(Average_N2P2 = mean(N2P2_waveform),Average_P3 = mean(P3_waveform) )
  

# Define the X-axis vertical lines
vertical_lines1 <- c(180, 320, 550)  # Specify the X-axis positions
# Define the X-axis vertical lines
vertical_lines2 <- c(400, 750)  # Specify the X-axis positions

#Red
line_colors <- c("NeutGo" = "#D6E4F0", "NeutNoGo" = "#0000CD", "NegGo" = "#FFB6B6", "NegNoGo" = "#FF0000")
# line_colors <- c("NeutGo" = "lightskyblue1", "NeutNoGo" = "mediumblue", "NegGo" = "pink1", "NegNoGo" = "red2")

# DRAW THE GRAPHS
CWNS_N2P2_waveform <- ggplot(data = subset(summary_waveforms, talkergroup_final == 0), 
aes(x = Time, y = Average_N2P2, color = Stimulus)) +
  geom_line(stat = "identity", size = 1.5) +
  labs(x = "Time (ms)", y = "Amplitude in Microvolts (Î¼V)") +
  scale_x_continuous(limits = c(-100, 900), breaks = seq(-100, 900, 100), position = "top") +
  scale_y_continuous(limits = c(-15, 2), breaks = seq(-14, 2, 2)) +
  scale_color_manual(values = line_colors, labels = c("Affective Go", "Affective NoGo","Neutral Go", "Neutral NoGo")) +  # Set line colors manually
  theme(
    axis.text = element_text(size = 14, color = "black"),
    axis.title = element_text(size = 14),
    plot.background = element_rect(fill = "white"),
    axis.line = element_line(linetype = "solid", color = "gray10", size = 1.4),
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    panel.background = element_blank(),
    legend.text = element_text(size = 12), 
    legend.title =element_blank()
    ) +
  geom_vline(xintercept = vertical_lines1, color = "gray50", linetype = "dashed") +
  geom_hline(yintercept = 0, color = "gray70", linetype = "dotted") +
  geom_vline(xintercept = 0, color = "gray70", linetype = "dotted") +
  ggtitle("CWNS N2P2 Activity") +
  theme(plot.title = element_text(hjust = 0.5, size = 24, face = "bold", vjust = 2)) +
  theme(legend.position = c(.85, .2))  # Set the position of the legend
plot(CWNS_N2P2_waveform)


CWS_N2P2_waveform <- ggplot(data = subset(summary_waveforms, talkergroup_final == 1), 
aes(x = Time, y = Average_N2P2, color = Stimulus)) +
  geom_line(stat = "identity", size = 1.3) +
  labs(x = "Time (ms)", y = "Amplitude in Microvolts (Î¼V)") +
  scale_x_continuous(limits = c(-100, 900), breaks = seq(-100, 900, 100), position = "top") +
  scale_y_continuous(limits = c(-15, 2), breaks = seq(-14, 2, 2)) +
  scale_color_manual(values = line_colors, labels = c("Affective Go", "Affective NoGo","Neutral Go", "Neutral NoGo")) +  # Set line colors manually
  theme(
    axis.text = element_text(size = 14 , color = "black"),
    axis.title = element_text(size = 14),
    plot.background = element_rect(fill = "white"),
    axis.line = element_line(linetype = "solid", color = "gray10", size = 1.4),
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    panel.background = element_blank(),
    legend.text = element_text(size = 12), 
    legend.title =element_blank()
  ) +
  geom_vline(xintercept = vertical_lines1, color = "gray50", linetype = "dashed") +
  geom_hline(yintercept = 0, color = "gray70", linetype = "dotted") +
  geom_vline(xintercept = 0, color = "gray70", linetype = "dotted") +
  ggtitle("CWS N2P2 Activity") +
  theme(plot.title = element_text(hjust = 0.5, size = 24, face = "bold", vjust = 2)) +
  theme(legend.position = c(.85, .2))  # Set the position of the legend
plot(CWS_N2P2_waveform)  


CWNS_P3_waveform <- ggplot(data = subset(summary_waveforms, talkergroup_final == 0), 
aes(x = Time, y = Average_P3, color = Stimulus)) +
  geom_line(stat = "identity", size = 1.3) +
  labs(x = "Time (ms)", y = "Amplitude in Microvolts (Î¼V)") +
  scale_x_continuous(limits = c(-100, 900), breaks = seq(-100, 900, 100), position = "top")+
  scale_y_continuous(limits = c(-2, 13), breaks = seq(-2, 13, 2)) +
  scale_color_manual(values = line_colors, labels = c("Affective Go", "Affective NoGo","Neutral Go", "Neutral NoGo")) +  # Set line colors manually
  theme(
    axis.text = element_text(size = 14, color = "black"),
    axis.title = element_text(size = 14),
    plot.background = element_rect(fill = "white"),
    axis.line = element_line(linetype = "solid", color = "gray10", size = 1.4),
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    panel.background = element_blank(),
    legend.text = element_text(size = 12), 
    legend.title =element_blank()
  ) +
  geom_vline(xintercept = vertical_lines2, color = "gray50", linetype = "dashed") +
  geom_hline(yintercept = 0, color = "gray70", linetype = "dotted") +
  geom_vline(xintercept = 0, color = "gray70", linetype = "dotted") +
  ggtitle("CWNS P3 Activity") +
  theme(plot.title = element_text(hjust = 0.5, size = 24, face = "bold", vjust = 2)) +
    theme(legend.position = c(.65, .3))
plot(CWNS_P3_waveform)

CWS_P3_waveform <- ggplot(data = subset(summary_waveforms, talkergroup_final == 1),
aes(x = Time, y = Average_P3, color = Stimulus)) +
  geom_line(stat = "identity", size = 1.3) +
  labs(x = "Time (ms)", y = "Amplitude in Microvolts (Î¼V)") +
  scale_x_continuous(limits = c(-100, 900), breaks = seq(-100, 900, 100), position = "top")+
  scale_y_continuous(limits = c(-2, 13), breaks = seq(-2, 13, 2)) +
  scale_color_manual(values = line_colors, labels = c("Affective Go", "Affective NoGo","Neutral Go", "Neutral NoGo")) +  # Set line colors manually
  theme(
    axis.text = element_text(size = 14 , color = "black"),
    axis.title = element_text(size = 14),
    plot.background = element_rect(fill = "white"),
    axis.line = element_line(linetype = "solid", color = "gray10", size = 1.4),
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    panel.background = element_blank(),
    legend.text = element_text(size = 12), 
    legend.title =element_blank()
  ) +
  geom_vline(xintercept = vertical_lines2, color = "gray50", linetype = "dashed") +
  geom_hline(yintercept = 0, color = "gray70", linetype = "dotted") +
  geom_vline(xintercept = 0, color = "gray70", linetype = "dotted") +
  ggtitle("CWN P3 Activity") +
  theme(plot.title = element_text(hjust = 0.5, size = 24, face = "bold", vjust = 2)) +
  theme(legend.position = c(.65, .3))
plot(CWS_P3_waveform)  

```





